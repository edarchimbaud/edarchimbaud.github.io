<html class="notion-html"><head lang="en"><meta charset="utf-8"/><meta content="width=device-width,height=device-height,initial-scale=1,maximum-scale=1,user-scalable=no,viewport-fit=cover" name="viewport"/><title>5. Class Imbalance, Outliers, and Distribution Shift</title><meta content="en_US" property="og:locale"/><link href="data:image/png;base64,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" rel="shortcut icon" type="image/x-icon"/><link href="/images/logo-ios.png" rel="apple-touch-icon"/><meta content="yes" name="apple-mobile-web-app-capable"/><meta content="telephone=no" name="format-detection"/><meta content="no" name="msapplication-tap-highlight"/><link href="assets/css/e218a1aef6df86309cb95b61e446888efa3b0379.css" media="print" rel="stylesheet"/><link href="assets/css/e7df85b6a5b33bc52629df6d3bd37d197c7a873d.css" rel="stylesheet"/><meta content="Edouard d'Archimbaud" name="title"/><meta content="Edouard d'Archimbaud official website" name="description"/><link href="assets/css/e1d809d762eeca23edf0cb31bb17bf3c703085f5.css" rel="stylesheet"/><style type="text/css"></style></head><body class="notion-body"><style>body{background:#fff}body.dark{background:#191919}@keyframes startup-shimmer-animation{0%{transform:translateX(-100%) translateZ(0)}100%{transform:translateX(100%) translateZ(0)}}@keyframes startup-shimmer-fade-in{0%{opacity:0}100%{opacity:1}}@keyframes startup-spinner-rotate{0%{transform:rotate(0) translateZ(0)}100%{transform:rotate(360deg) translateZ(0)}}#initial-loading-spinner{position:fixed;height:100vh;width:100vw;z-index:-1;display:none;align-items:center;justify-content:center;opacity:.5}#initial-loading-spinner svg{height:24px;width:24px;animation:startup-spinner-rotate 1s linear infinite;transform-origin:center center;pointer-events:none}#skeleton{background:#fff;position:fixed;height:100vh;width:100vw;z-index:-1;display:none;overflow:hidden}#initial-loading-spinner.show,#skeleton.show{display:flex}body.dark #skeleton{background:#191919}.notion-front-page #skeleton,.notion-mobile #skeleton{display:none}#skeleton-sidebar{background-color:#fbfbfa;box-shadow:inset -1px 0 0 0 rgba(0,0,0,.025);display:flex;width:240px;flex-direction:column;padding:12px 14px;overflow:hidden}body.dark #skeleton-sidebar{background-color:#202020;box-shadow:inset -1px 0 0 0 rgba(255,255,255,.05)}#skeleton.isElectron #skeleton-sidebar{padding-top:46px}#skeleton .row{display:flex;margin-bottom:8px;align-items:center}#skeleton .row.fadein{animation:1s ease-in 0s 1 normal both running startup-shimmer-fade-in}#skeleton .chevron{width:12px;height:12px;display:block;margin-right:4px;fill:rgba(227,226,224,.5)}body.dark #skeleton .chevron{fill:#2f2f2f}.startup-shimmer{background:rgba(227,226,224,.5);overflow:hidden;position:relative}body.dark .startup-shimmer{background:#2f2f2f}.startup-shimmer::before{content:"";position:absolute;height:100%;width:100%;z-index:1;animation:1s linear infinite startup-shimmer-animation;background:linear-gradient(90deg,transparent 0,rgba(255,255,255,.4) 50%,transparent 100%)}body.dark .startup-shimmer::before{background:linear-gradient(90deg,transparent 0,rgba(86,86,86,.4) 50%,transparent 100%)}#skeleton .icon{width:20px;height:20px;border-radius:4px}#skeleton .text{height:10px;border-radius:10px}#skeleton .draggable{-webkit-app-region:drag;position:absolute;top:0;left:0;width:100%;height:36px;display:none}#skeleton.isElectron .draggable{display:block}</style><style id="scroll-properties"></style><div id="notion-app"><div class="notion-app-inner notion-light-theme" style='color: rgb(55, 53, 47); fill: currentcolor; line-height: 1.5; font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; -webkit-font-smoothing: auto; background-color: white;'><div style="height: 100%;"><div class="notion-cursor-listener" style="width: 100vw; height: 100%; position: relative; display: flex; flex: 1 1 0%; background: white; cursor: text;"><div class="" style="display: flex; flex-direction: column; width: 100%; overflow: hidden;"><div style="max-width: 100vw; z-index: 100; background: white; user-select: none;"><div class="notion-topbar" style="width: 100%; max-width: 100vw; height: 45px; opacity: 1; transition: opacity 700ms ease 0s, color 700ms ease 0s; position: relative;"><div style="display: flex; justify-content: space-between; align-items: center; overflow: hidden; height: 45px; padding-left: 12px; padding-right: 10px;"><div class="notranslate" style="display: flex; align-items: center; line-height: 1.2; font-size: 14px; height: 100%; flex-grow: 0; margin-right: 8px; min-width: 0px;"><div class="notion-selectable notion-page-block" data-block-id="d8397a78-1321-456c-9c10-1feea7a42b60" style="display: flex; align-items: center; min-width: 0px;"><a href="edouard-d-archimbaud.html" rel="noopener noreferrer" style="display: flex; text-decoration: none; user-select: none; cursor: pointer; color: inherit; min-width: 0px;"><div role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: inline-flex; align-items: center; flex-shrink: 1; white-space: nowrap; height: 24px; border-radius: 4px; font-size: inherit; line-height: 1.2; min-width: 0px; padding: 2px; color: rgb(55, 53, 47);" tabindex="0"><div style="display: flex; align-items: center; min-width: 0px;"><div class="notion-record-icon notranslate" style="display: flex; align-items: center; justify-content: center; height: 20px; width: 20px; border-radius: 0.25em; flex-shrink: 0; margin-right: 6px; font-weight: 500;"><div style="display: flex; align-items: center; justify-content: center; height: 20px; width: 20px;"><div style="height: 18px; width: 18px; font-size: 18px; line-height: 1; margin-left: 0px; color: black;"><span aria-label="üë®‚Äçüíª" role="img" style='font-family: "Apple Color Emoji", "Segoe UI Emoji", NotoColorEmoji, "Noto Color Emoji", "Segoe UI Symbol", "Android Emoji", EmojiSymbols; line-height: 1em; white-space: nowrap;'>üë®‚Äçüíª</span></div></div></div><div class="notranslate" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; max-width: 160px;">Edouard d‚ÄôArchimbaud</div></div></div></a></div><span style="margin-left: 2px; margin-right: 2px; color: rgba(55, 53, 47, 0.5);">/</span><div class="notion-selectable notion-page-block" data-block-id="bb024d08-b3b1-4dbd-bafc-0fa8d6a316c2" style="display: flex; align-items: center; min-width: 0px;"><a href="data-centric-ai.html" rel="noopener noreferrer" style="display: flex; text-decoration: none; user-select: none; cursor: pointer; color: inherit; min-width: 0px;"><div role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: inline-flex; align-items: center; flex-shrink: 1; white-space: nowrap; height: 24px; border-radius: 4px; font-size: inherit; line-height: 1.2; min-width: 0px; padding: 2px; color: rgb(55, 53, 47);" tabindex="0"><div style="display: flex; align-items: center; min-width: 0px;"><div class="notion-record-icon notranslate" style="display: flex; align-items: center; justify-content: center; height: 20px; width: 20px; border-radius: 0.25em; flex-shrink: 0; margin-right: 6px; font-weight: 500;"><div style="display: flex; align-items: center; justify-content: center; height: 20px; width: 20px;"><div style="height: 18px; width: 18px; font-size: 18px; line-height: 1; margin-left: 0px; color: black;"><span aria-label="üéØ" role="img" style='font-family: "Apple Color Emoji", "Segoe UI Emoji", NotoColorEmoji, "Noto Color Emoji", "Segoe UI Symbol", "Android Emoji", EmojiSymbols; line-height: 1em; white-space: nowrap;'>üéØ</span></div></div></div><div class="notranslate" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; max-width: 160px;">Data-centric AI</div></div></div></a></div><span style="margin-left: 2px; margin-right: 2px; color: rgba(55, 53, 47, 0.5);">/</span><div role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: inline-flex; align-items: center; flex-shrink: 1; white-space: nowrap; height: 24px; border-radius: 4px; font-size: 14px; line-height: 1.2; min-width: 0px; padding-left: 6px; padding-right: 6px; color: rgb(55, 53, 47);" tabindex="0"><div class="notion-record-icon notranslate" style="display: flex; align-items: center; justify-content: center; height: 20px; width: 20px; border-radius: 0.25em; flex-shrink: 0; margin-right: 6px;"><div style="display: flex; align-items: center; justify-content: center; height: 20px; width: 20px;"><div style="height: 18px; width: 18px; font-size: 18px; line-height: 1; margin-left: 0px; color: black;"><span aria-label="üéì" role="img" style='font-family: "Apple Color Emoji", "Segoe UI Emoji", NotoColorEmoji, "Noto Color Emoji", "Segoe UI Symbol", "Android Emoji", EmojiSymbols; line-height: 1em; white-space: nowrap;'>üéì</span></div></div></div><span class="notranslate" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; max-width: 240px;">5. Class Imbalance, Outliers, and Distribution Shift</span></div></div><div style="flex-grow: 1; flex-shrink: 1;"></div><div role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: inline-flex; align-items: center; flex-shrink: 0; white-space: nowrap; height: 28px; border-radius: 4px; font-size: 14px; line-height: 1.2; min-width: 0px; padding-left: 8px; padding-right: 8px; color: rgb(55, 53, 47);" tabindex="0"><svg class="searchNew" style="width: 14px; height: 14px; display: block; fill: inherit; flex-shrink: 0; backface-visibility: hidden; margin-right: 6px;" viewBox="0 0 17 17"><path d="M6.78027 13.6729C8.24805 13.6729 9.60156 13.1982 10.709 12.4072L14.875 16.5732C15.0684 16.7666 15.3232 16.8633 15.5957 16.8633C16.167 16.8633 16.5713 16.4238 16.5713 15.8613C16.5713 15.5977 16.4834 15.3516 16.29 15.1582L12.1504 11.0098C13.0205 9.86719 13.5391 8.45215 13.5391 6.91406C13.5391 3.19629 10.498 0.155273 6.78027 0.155273C3.0625 0.155273 0.0214844 3.19629 0.0214844 6.91406C0.0214844 10.6318 3.0625 13.6729 6.78027 13.6729ZM6.78027 12.2139C3.87988 12.2139 1.48047 9.81445 1.48047 6.91406C1.48047 4.01367 3.87988 1.61426 6.78027 1.61426C9.68066 1.61426 12.0801 4.01367 12.0801 6.91406C12.0801 9.81445 9.68066 12.2139 6.78027 12.2139Z"></path></svg>Search</div><div role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: inline-flex; align-items: center; flex-shrink: 0; white-space: nowrap; height: 28px; border-radius: 4px; font-size: 14px; line-height: 1.2; min-width: 0px; padding-left: 8px; padding-right: 8px; color: rgb(55, 53, 47);" tabindex="0">Duplicate</div><div role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: flex; align-items: center; justify-content: center; width: 32px; height: 28px; border-radius: 3px;" tabindex="0"><svg class="dots" style="width: 18px; height: 18px; display: block; fill: inherit; flex-shrink: 0; backface-visibility: hidden;" viewBox="0 0 13 3"><g><path d="M3,1.5A1.5,1.5,0,1,1,1.5,0,1.5,1.5,0,0,1,3,1.5Z"></path><path d="M8,1.5A1.5,1.5,0,1,1,6.5,0,1.5,1.5,0,0,1,8,1.5Z"></path><path d="M13,1.5A1.5,1.5,0,1,1,11.5,0,1.5,1.5,0,0,1,13,1.5Z"></path></g></svg></div><div style="flex: 0 0 auto; width: 1px; height: 16px; margin-left: 8px; margin-right: 8px; background: rgba(55, 53, 47, 0.16);"></div><div role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: inline-flex; align-items: center; flex-shrink: 0; white-space: nowrap; height: 28px; border-radius: 4px; font-size: 14px; line-height: 1.2; min-width: 0px; padding-left: 8px; padding-right: 8px; color: rgb(55, 53, 47);" tabindex="0"><svg class="notionLogo" style="width: 18px; height: 18px; display: block; fill: inherit; flex-shrink: 0; backface-visibility: hidden; margin-right: 6px;" viewBox="0 0 120 126"><path d="M 20.6927 21.9315C 24.5836 25.0924 26.0432 24.8512 33.3492 24.3638L 102.228 20.2279C 103.689 20.2279 102.474 18.7705 101.987 18.5283L 90.5477 10.2586C 88.3558 8.55699 85.4356 6.60818 79.8387 7.09563L 13.1433 11.9602C 10.711 12.2014 10.2251 13.4175 11.1939 14.3924L 20.6927 21.9315ZM 24.8281 37.9835L 24.8281 110.456C 24.8281 114.351 26.7745 115.808 31.1553 115.567L 106.853 111.187C 111.236 110.946 111.724 108.267 111.724 105.103L 111.724 33.1169C 111.724 29.958 110.509 28.2544 107.826 28.4976L 28.721 33.1169C 25.8018 33.3622 24.8281 34.8225 24.8281 37.9835ZM 99.5567 41.8711C 100.042 44.0622 99.5567 46.2512 97.3618 46.4974L 93.7143 47.2241L 93.7143 100.728C 90.5477 102.43 87.6275 103.403 85.1942 103.403C 81.2983 103.403 80.3226 102.186 77.4044 98.54L 53.5471 61.087L 53.5471 97.3239L 61.0964 99.0275C 61.0964 99.0275 61.0964 103.403 55.0057 103.403L 38.2148 104.377C 37.727 103.403 38.2148 100.973 39.9179 100.486L 44.2996 99.2717L 44.2996 51.36L 38.2158 50.8725C 37.728 48.6815 38.9431 45.5225 42.3532 45.2773L 60.3661 44.0631L 85.1942 82.0036L 85.1942 48.4402L 78.864 47.7136C 78.3781 45.0351 80.3226 43.0902 82.7569 42.849L 99.5567 41.8711ZM 7.5434 5.39404L 76.9175 0.285276C 85.4366 -0.445402 87.6285 0.0440428 92.983 3.93368L 115.128 19.4982C 118.782 22.1747 120 22.9034 120 25.8211L 120 111.187C 120 116.537 118.051 119.701 111.237 120.185L 30.6734 125.05C 25.5584 125.294 23.124 124.565 20.4453 121.158L 4.13735 99.9994C 1.21516 96.1048 0 93.191 0 89.7819L 0 13.903C 0 9.5279 1.94945 5.8785 7.5434 5.39404Z"></path></svg>Try Notion</div></div></div><div style="width: calc(100% - 0px); user-select: none;"></div></div><div class="notion-frame" style="flex-grow: 0; flex-shrink: 1; display: flex; flex-direction: column; background: white; z-index: 1; height: calc(100vh - 45px); max-height: 100%; position: relative; width: 1920px;"><div class="notion-scroller vertical" style="display: flex; flex-direction: column; z-index: 1; flex-grow: 1; position: relative; align-items: center; margin-right: 0px; margin-bottom: 0px; overflow: hidden auto;"><div style="position: absolute; top: 0px; left: 0px;"><div></div></div><div class="whenContentEditable" data-content-editable-root="true" style="caret-color: rgb(55, 53, 47); width: 100%; display: flex; flex-direction: column; position: relative; align-items: center; flex-grow: 1; --whenContentEditable--WebkitUserModify:read-write-plaintext-only;"><span style="height: 1px; width: 1px;"></span><div class="pseudoSelection" contenteditable="false" data-content-editable-void="true" style="user-select: none; --pseudoSelection--background:transparent; width: 100%; display: flex; flex-direction: column; align-items: center; flex-shrink: 0; flex-grow: 0; z-index: 2;"></div><div style="width: 100%; display: flex; justify-content: center; z-index: 3; flex-shrink: 0;"><div style="max-width: 100%; min-width: 0px; width: 900px;"><div style="width: 100%; display: flex; flex-direction: column; align-items: center; flex-shrink: 0; flex-grow: 0;"><div style="max-width: 100%; padding-left: calc(96px + env(safe-area-inset-left)); width: 100%;"><div class="pseudoSelection" contenteditable="false" data-content-editable-void="true" style="user-select: none; --pseudoSelection--background:transparent; pointer-events: none;"><div class="notion-record-icon notranslate" style="display: flex; align-items: center; justify-content: center; height: 78px; width: 78px; border-radius: 0.25em; flex-shrink: 0; position: relative; z-index: 1; margin-left: 3px; margin-bottom: 0px; margin-top: 96px; pointer-events: auto;"><div style="display: flex; align-items: center; justify-content: center; height: 78px; width: 78px;"><div style="height: 78px; width: 78px; font-size: 78px; line-height: 1; margin-left: 0px; color: black;"><span aria-label="üéì" role="img" style='font-family: "Apple Color Emoji", "Segoe UI Emoji", NotoColorEmoji, "Noto Color Emoji", "Segoe UI Symbol", "Android Emoji", EmojiSymbols; line-height: 1em; white-space: nowrap;'>üéì</span></div></div></div><div class="notion-page-controls" style='display: flex; justify-content: flex-start; flex-wrap: wrap; margin-top: 8px; margin-bottom: 4px; margin-left: -1px; color: rgba(55, 53, 47, 0.5); font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; height: 24px; pointer-events: auto;'></div></div><div style="padding-right: calc(96px + env(safe-area-inset-right));"><div><div class="notion-selectable notion-page-block" data-block-id="5cc36569-d7fc-47c9-9270-c6dddbee058f" style='color: rgb(55, 53, 47); font-weight: 700; line-height: 1.2; font-size: 40px; font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; cursor: text; display: flex; align-items: center;'><div contenteditable="false" data-content-editable-leaf="true" placeholder="Untitled" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">5. Class Imbalance, Outliers, and Distribution Shift</div></div><div style="margin-left: 4px;"></div></div></div></div></div><div style="width: 100%; display: flex; flex-direction: column; align-items: center; flex-shrink: 0; flex-grow: 0;"><div contenteditable="false" data-content-editable-void="true" style="padding-left: calc(96px + env(safe-area-inset-left)); padding-right: calc(96px + env(safe-area-inset-right)); max-width: 100%; width: 100%;"></div></div></div></div><main style="display: flex; width: 100%; justify-content: center; padding-top: 5px;"><div style="max-width: 100%; min-width: 0px; width: 900px;"><div class="notion-page-content" style="flex-shrink: 0; flex-grow: 1; max-width: 100%; display: flex; align-items: flex-start; flex-direction: column; font-size: 16px; line-height: 1.5; width: 100%; z-index: 4; padding-bottom: 30vh; padding-left: calc(96px + env(safe-area-inset-left)); padding-right: calc(96px + env(safe-area-inset-right));"><div class="notion-selectable notion-text-block" data-block-id="d940d993-f3ab-44f7-acb5-2aad4a0047eb" style="width: 100%; max-width: 1728px; margin-top: 2px; margin-bottom: 0px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">All right, let's get started. Uh, good afternoon, everybody, and welcome back to Week Two of Introduction to Data Centric AI In today's lecture, we're going to cover three common problems present in real world machine learning: data sets: class imbalance, outliers, and distribution shift. Also, I'm hoping for this lecture to be really interactive, almost more like a discussion than a lecture. So please, uh, feel free to want to ask questions. Just shout out answers to my questions. and please ask lots of your own questions as I go through this. I'm gonna. There's a lot of interesting material in this lecture. I'm going to try to get through all of it, but I'm going to go pretty fast, so ask questions whenever things are confusing. All right. So let's start with class imbalance. Just from this name, can anybody guess what class imbalance means? One of my class imbalance be a challenge. What is class imbalance? Yeah. [Music] Yeah, so those are two slightly different things. But yes, the first answer is the one we're going for here, and then the second thing we're going to talk about at the end of this lecture. So yeah, class imbalance is when certain classes in your data set are more prevalent than others. I Think the canonical example of imbalance classes is a fraud detection task. so Banks deal with credit card transactions and some of those transactions are fraudulent. And so they use machine learning to try to figure out which ones are fraudulent so they can block them so they don't lose money on those transactions. But it's not the case that fraudulent transactions are present at the same ratio as non-fraudulent transactions in real world data. This might be as skewed as like 98 point or 99.8 percent of transactions are benign and only 0.2 percent are fraudulent. So can anybody think of any other examples of real problems where there's class imbalance? [Music] Yeah, exactly. medical diagnoses. So if you're trying to say predict the presence of a certain type of medical issue among the general population like, say, a certain type of cancer like most people don't have that cancer and so there's going to be a big imbalance between positives and negatives. Foreign. let's try to go for one more. Any other ideas? Sure, Yeah, so car crashes and self-driving car data. So yeah, in general, self-driving cars might see a lot of different types of things on the road, and certain events on the road are less prevalent than others, right? Like self-driving cars probably see people changing lanes all the time or turning all the time, but crashes are hopefully a little bit more rare than those more common events. So uh, we talked about something really similar. In a previous lecture, we talked about the topic of underperforming subpopulations. So does anybody know what the differences between underperforming subpopulations and class imbalance? The related topics, but not quite the same. Foreign is when there's a different prevalence of different Uh classes in the data set Where classes are like the things we're trying to predict, right? Like with fraud detection, fraud versus not fraud, whereas underperforming subpopulations is concerned with various slices of the data that don't line up with the classes. So for example, I think the medical diagnosis one is a really interesting example. So there's class imbalance there. Like that's a challenge. But you might also have a problem with underperforming subpopulations. Like maybe in your data set, you do a better job of detecting a certain type of issue in men versus women or with people of a certain race or something like that. So men versus women that doesn't appear in the label, right? The label is just like positive or negative. Does someone have a certain type of issue? Um, but it may still be affected by these other slices of the data. All right. So what are some of the challenges with class imbalance? One of the first things that you run into is evaluation. We talked a little bit about this last lecture. but what might be the challenge with evaluating a machine learning model that you train on an imbalanced data set? Yeah, like [Music] just not flooding or party passing. Cave Uh, balanced hydration might better show you like from amount of time to make predicted. Yeah, exactly. So the challenge is that just looking at standard evaluation metrics like accuracy may not make sense in these settings. So with fraud detection, if your metric is just accuracy and 99.8 percent of transactions are not fraudulent, then a classifier that always predicts not fraud which is probably not what you want is going to have really high accuracy, right? So one of the first things you need to do when dealing with such a problem is Define an appropriate evaluation metric for your problem. And there's no one-size-fits-all solution there. but there are a couple different things you can consider and one thing we'll talk about in this lecture is a score called the F Beta Score. So first, a little bit of review, hopefully something you've covered in 6036 or similar machine learning class. Can anybody tell me what these metrics are? Precision and recall And here we're focusing on binary classification problems. So like the fraud detection example or the medical diagnosis example where we're trying to figure out if it's positive or negative, these are two metrics. Kind of like accuracy is a metric. These are two other metrics that you might have studied before. So Precision is looking at What Proportion of things that were flagged positive are actually positive. So that's the true positive rate over the true positives. Uh, plus the false positives, right? Like all the things you flagged, what percentage of them are actually positive. And then the recall is What Proportion of actual positives were identified correctly. So that's the true positives. Uh, whoops, Uh yeah, that's the true positives over the true positives. plus false negatives, right? So these are all the positive things. the ones you found in the ones you didn't find and then these are the ones you found are flagged. So these are two different metrics you might be interested in. And when we're dealing with a binary classification problem where there's class imbalance, we might want to have a summary score or metric that we're trying to optimize that balances the trade-off between these two things. And so a common score to use there is uh, does anybody know about this? I might have covered it before. Yeah, Yeah, exactly. So one score you see that combines these two things is the F1 score, the harmonic mean of precision and recall when dealing with imbalanced classes. A related metric that is useful is the F Beta score and so that's defined as so it's parametrized by this parameter beta, and it basically allows you to control the trade-off between precision and recall. All right. So here's the formula for f beta score. When beta equals one, then this just turns into your F1 score. And so to understand this a little bit better, let's think about a particular problem and think about how we might want to tune beta in order to choose an appropriate evaluation metric for our problem. So some of you are probably here at MIT over the last couple years and once covet hit MIT started regularly making people take covid tests right. and then if the test came out positive, you had to stay home and take your classes over Zoom for a week or something like that, right? And so those covet tests aren't perfect, right? Like, the covet test itself has some false positive rate. and so if you don't have Covid but your flag positive, it's going to be kind of annoying for you because you're going to have to stay home and take classes over Zoom right? And so that's one possible bad outcome. The other possible bad outcome is a false negative, right? You might actually have Covid, but the test doesn't flag you as positive And so you go into class and uh, now you've gotten everybody around you sick And so does anybody have any idea in that particular scenario, would you want to weigh Precision or recall more heavily? Like for that particular case, What's more problematic is it more problematic to stay at home when you don't need to, Or is it more problematic if you miss a positive covid case? Yeah, exactly. It's probably more problematic to miss a positive covet case. It's not too inconvenient to watch lectures from home, and so in that scenario, what? Uh, what would you want to choose for beta? Like would you want to choose one something higher than one or something less than one. So if you choose a bigger beta that weighs Precision uh, more heavily, right? Yeah, Yeah, and yeah, so you'd want to. Yeah, Optimize for having more false positives for this particular problem. and in general you, there's no one-size-fits-all solution. So if you're applying this to say, fraud detection or something you'd need to actually understand like, oh, what are the costs of missing a fraudulent transaction, What are the costs of blocking a benign transaction And yeah, there's some domain knowledge and understanding of the problem that's required there. All right. So once we have an evaluation metric, what do we do next? Well, we can train a machine learning model and evaluate it right. And so one thing we could try on an imbalanced data set is just train a model in the standard way and just see how it does on the evaluation metric. And in some cases it might just work out fine. And if that's the case, well, then you're done like it does well in the evaluation metric. But if not, there are some techniques you can use to try to improve the performance on the evaluation metric you care about when dealing with heavily imbalanced data sets. What's kind of cool is a lot of these techniques are they're pretty intuitive, so I'm sure you could figure out some of them just on your own without even looking at the lecture notes, so you can think about that for a moment. We'll go through a couple of them right now. So just off the top of their heads, off the off the top of your heads, can any of you just come up with some idea that might be a reasonable thing to try if you have class imbalance. Like if this fraud detection data set I Think if you trained a classifier on the standard way to probably just predict, not fraud, so what might you try to train a better classifier for your problem? Yeah, yeah. so dropping out? Not fraud cases in your training set. And so that's a technique called under sampling. So this might seem a little bit weird. like you have a big data set now you're going to throw some of it away. but this actually works surprisingly well in practice for addressing this problem. Any any other ideas? Yeah, exactly. Another idea is oversampling the minority class rather than dropping out examples of the majority class. And so yeah, this works well in some settings. And uh, yeah, just depending on the application, you might need to be careful. Like sometimes this works well. Sometimes this can result in unstable training, so you might want to use different techniques. Any other ideas? Yeah. [Music] You could create synthetic data for the underrepresented class. and so there's various data set augmentation techniques, right? Maybe you've studied ones related to images because those are very intuitive. If you have one image and you can take that same image and rotate it or translate it or skew it or things like that just to get many more examples that still have the same label, but they're different examples so it'll improve model training any other ideas. So another one that you might see sometimes is something called sample weights foreign and this one's You can think of it almost like over sampling or related to oversampling and under sampling. but if you have a loss function, that's the sum of per data point losses instead of having your loss function, just be the sum of your per data point losses. You can multiply it by sample dependent weights and you can choose these weights so that you underweight the majority class or overweight the minority class. And so these three techniques are all related to each other and you can think about on your own whether or not they're equivalent and in some settings they are so like in linear regression. Um, doing sample weights say like multiplying the weight of the minority class by two is the same as oversampling by duplicating all those examples, but in other settings they might not be exactly the same. Like say you're training a neural net with mini batch gradient descent. then the it's not going to give you exactly the same results though they're still related. And So Speaking of neural, Nets There's one other technique I'll briefly mention which is balanced mini batch training foreign And so this is when you're training a neural network or something like that, where you train in many batches. So you're doing training steps with a subset of your data at a time. and when choosing that subset of data instead of sampling uniformly at random across the entire data set, you will wait how you choose that data such that you will have an over representation of the minority class. So you can end up with 50 50 positives and negatives in the mini batch. And so again, these are very similar to these other methods we've talked about. Like awaiting a minority class is similar to oversampling, but not quite the same, right? Like, you won't end up with the same data point twice in a mini batch with this technique, whereas you might with oversampling. And you can also, of course, combine these different techniques, and often a combination of this ends up working better in practice than any one technique on its own. All right. So that's our Whirlwind tour of class imbalance. Any any questions about that before we move on to outliers. Awesome. Let's move on then. can anybody tell me just informally, What is an outlier? You've probably heard the term before. An outlier anomaly? Yeah, exactly. It's a data point that doesn't fit the distribution. It's a data point that doesn't look like the rest of the data. This is very easy to show in picture form. Like, okay, if I have some data, say it's two-dimensional data. So here's a X1 and X2 axis and I have some samples here that are negative class, Some samples here that are a positive class and then there's a positive example here. Just as a as a human, looking at this data, you can be like, oh, this thing is not like the rest. This is the outlier. See outliers are data points that differ significantly from the other data points in your data set. How I How might we end up with outliers in our data? Any ideas? Yeah, yeah. bad sensors. That's one example. Say collecting data with an air quality sensor and it rained. and the sensor is not super resistant to rain. so the electronics are messed up and now it's giving us funny data. Any other ideas? Yeah, gaps in data? Sure. For example, you might have missing fields in a tabular data set. So say you have a data set of student grades and the TA just forgot to enter some of the grades so they're just null values there. Any other ideas? Yeah, yeah, it can be statistically significant depending on the problem. I'll summarize that. refer to that too. Just rare events. So notice that this is a little bit different than these two. Like, if we have outliers that are a result of bad sensors or gaps in data like these, we probably just want to throw out. They're just nonsense the gaps in data Maybe we want to fix by filling in the missing fields. Or if that's not possible, maybe it makes the most sense to drop them. But rare events? Those things we don't want to drop right like your self-driving car data set. You maybe have some rare things going on. If you drop those like, you will not be able to handle those sorts of things in production, right? So any ideas how you distinguish between these and these is it possible to do automatically? Yeah, So that's part of the challenge with outliers is that it's not always the case that you can automatically tell whether or not a particular event or particular data point is a rare event or if it's bad data on what type of bad data it is. And so dealing with outliers often involves like one step which is finding outliers and then a second step which is handling the outliers and often that takes some extra work. It's not just an automatic thing, like throw them all away. Some of you have taken 6036 I Think in that class, you covered some techniques to deal with outliers, but those are very model-centric techniques, right? So you talked about how different loss functions might be more or less resistant to outliers, right? Like say, using L1 loss versus L2 loss. So that's not what we're going to do in today's lecture. We're going to focus more on the data Centric side of outliers and in particular, focusing on identifying outliers. I'm going to be a little bit more precise here and defining some terminology. There are a couple related problems in identifying outliers that have a slightly different setup, and it's helpful to talk through them and understand what the difference is. I've been using the term outlier more generally and I will do so throughout the rest of the lecture, but for the purpose of describing this task, the task of outlier detection is when you have an unlabeled data set so there's just a bunch of data and you want to figure out which subset of the data is out of distribution with the rest. This might be like you just have a bunch of data points I'm just going to draw these as X's There's no labels or anything like that. There's no notion of what is the clean data, what is in distribution data versus what is not. There's just a data set and you want to figure out the subset of points that don't fit the rest. And then there's this related task of anomaly detection. So an anomaly detection. You're given the in distribution set separately. so you have a bunch of data points x I that are defined to be in distribution and now given a new data point say x star, you want to determine whether it belongs to this distribution or not. So you see how these two things are. They seem very similar, but they're slightly different problems. One question is to check your understanding is how what makes anomaly detection different from a standard supervised learning classification problem? Like why is this not just binary classification like given a data point is an outlier or not. Yeah, you wouldn't know what sort of things out allow your trip that one is in the distribution? Yeah, yeah, that's exactly right. and I can I'll try to make that a little bit more precise. In in this setting, it's not like we have a set of indistribution examples and a set of out of distribution examples and we can use those to train on. It's not like we have labels associated with these like all in distribution and like a bunch of extra stuff which tells us what out of distribution data might look like. We only have the in distribution set and then given new data we have to decide whether it belongs to that set or not. So there's slightly different problems. Wait So so I know the detection happens like um, like and I wanted to actually advice to you when you get the new data and you're trying to find the class Center at Advanced Team understandable. Like the difference between the two Steel Yeah, okay, so I can. So what's the difference between anomaly detection and binary classification? Oh oh okay. so between this and this, Yeah, yeah. so here you're given a set of data that's defined as the in distribution set. You know all of it is in distribution, so say you're trying to distinguish pictures of animals from pictures of non-animals You might be given a data set that you're told like okay this is all pictures of animals and now I give you some random image that I found find on the internet and your task is to decide whether it's an animal. Is it like the things in this set or not Whereas in this task you're just given a data set like here's a bunch of images and I tell you which images are like most of the other images in the data set and which is which images are not. So it might be like I give you a data set of 95 animals but there's some random garbage mixed in there and you don't really have the the You can think of this as like a training set. you don't really have that in this setting. Outline detection was closer to just like a clustering problem where you're trying to find what's not in the main cluster. Yeah, so the question is is that lawyer detection like a clustering problem? Uh and yeah, clustering is one technique you can use to find outliers. Yeah, and uh, you can. Also there's if you think about this, you can actually cast anomaly detection problem as an outlier detection problem because you could always just combine this data set with this data point and then use an outlier detection algorithm to find the outliers. And then if this data point happens to be not identified by this algorithm used here, then you can flag it as an anomaly. But oftentimes, depending what you're doing, it probably makes sense to actually treat an anomaly detection problem as an anomaly detection problem. And there may be algorithms that perform better here. Just like given that you, this is additional information that you have right that you don't have here, right? Any questions so far? All right. So let's get into the interesting stuff: How do you actually find outliers? And so there's tons and tons of research on this. I Can't cover all the research, but we can talk through a couple different algorithms that you can use to find outliers. I'll go through some really simple ones just so we can build up some intuition and then after that, I'll describe some more practical ones. I Know this is a good part of the lecture to pay attention to because the lab assignment is all about outliers and I think we have a really fun lab assignment for today. All right. So um, mixing up my pages here? All right. let's start really simple. Here's an algorithm. Uh, it's a simple method devised by John Tukey in 1977. this is one of the people who invented the fast Fourier transform by the way, to identify outliers and this is concerned with just real valued scalar data. We can use this to build some intuition. All right. So suppose we have a bunch of data on the real line I'm going to draw the data as just little lines here, so we might have some data spread out like this. Whatever different clusters of data, we can look at this immediately. It has some structure. Maybe it doesn't. Yeah, there's some data. And what this algorithm does is it looks at the two quartiles. So it looks at basically like you sort the data and then you look at the the lower quartile. This is q1. Then you look at the upper quartile. This is Q3. Then this is defined this range. The difference between them is the interquartile range and then what you do is you look at a certain distance from each of these things. Suppose there's more data out here, so maybe you want to look at 1.5 times the interquartile range on either side and then these are your cutoffs. and then you say that this is in distribution and then anything below here or above here is out of distribution. All right. Simple puristic way to find out. Liars Another simple one. Just continuing to build some intuition is the Z-score this one people might have heard of. Does anybody know what this is? Anybody want to tell us what this is? Yeah. [Music] Yeah, exactly. So the Z-score is for a particular data point I is you take the data point, you subtract the the mean, and you divide by the standard deviation and then if your score is greater than some threshold, then you say that's an outlier and this is often chosen as like some number like three. And the idea here is that if your data is normally distributed here, I'm just going to draw data with uh, mean of zero and if you look at standard deviations, one standard deviation, two three, um, you're going to have with normally distributed data 99.8 percent of that in here and then anything that's in this part or in this part you consider an outlier, make sense. Yeah, so and it depends on your data set. If you're dealing with non-normally distributed data, maybe it'll work, maybe it won't Uh, it's like only valid to use with normally distributed data and also it usually only makes sense with low dimensional data. like if you imagine applying well I Guess either one of these techniques to like, say, image data using just raw pixels as the values. Like you're not really going to get sensible results. Is there an extension of the Z-score to a mixture of Gaussian? so like you can do the same thing in multiple? Dimensions Yeah, and so people do use these things in practice for oh another cool thing you can do with these is you also don't have to apply them to the entire data. One thing you can do is just look at individual features. So it might be that a particular feature has outliers in particular for a particular data set. So you could look at, say, a column of a tabular data set and apply this Z-score technique and find out wires there? Yeah. so these are useful simple data or tabular data are applied to individual features. And now we'll talk about a couple slightly more fancy methods. And again, this is kind of a random sample of outlier detection methods. There are lots of papers and like lots of algorithms implemented in libraries like Scikit, Learn and there's some links in the lecture notes that go into the details on those. So another neat algorithm this one's pretty simple to explain is intuitive and kind of interesting is something called isolation Forest So at a high level or intuitively the idea here is that if you have a random decision tree, then for uh, and then if you take all your data and you see like how far down the decision tree you need to go in order to end up with only that single piece of data isolated from the rest of the data, then the more outlier data like, the more the data is an outlier, the less down you'll need to go down your decision tree. Um, that might sound kind of confusing. It's probably easier if I just draw this out. So here we will consider two-dimensional data. So here's the X1 axis. Here's an X2 axis and I'm going to draw a bunch of data points as dots. right? And so when we look at this, we're like, okay, there seem to be two clusters here, and this one data point out here. that's an outlier, right? So how does isolation Forest automatically find this? Oh what it does. The algorithm at a high level is take the entire data set, choose a feature at random, choose a cut off at random, and then make that a decision boundary in your decision tree. And so I'm going to not choose these at random because I don't want to take forever to split this up. So I'll choose. Suppose like suppose you get lucky and we randomly choose like X2 equals 0.5 as one of our uh, boundaries. Okay, so now our decision tree is like X2 is less than 0.5 and then whatever, we might continue down. So maybe in this branch of the decision tree we might split X1 is less than 0.3 and continue going down here. But maybe in this part of the decision tree we'll split on X1 is less than 0.7 And then you see how here in this part of the decision tree that we've isolated one data point all by itself, right? Whereas you can see that here, it'll probably take longer to get down to just a single data point per tree node and so at a high level. That's how the isolation Forest algorithm works. Foreign. So taking a step back we might think about how we could apply this to various data sets. You can think about how you could apply this to say, a tabular data set. But would it make sense to apply this directly to say, an image data set where we're just working with raw pixel values as our as our data. So we have lots and lots of features. Like every axis is a pixel value or Channel Yeah, exactly. so it probably wouldn't The answer is that probably wouldn't make that much sense and you'd probably want to embed your image into a lower dimensional space. where like the the place where the image ends up in that embedding space. Um, yeah, it's actually a similar images are clustered near each other and we'll talk a little bit more about that in a moment. after talking about one final algorithm that we're going to cover. and also note that so far all the methods we've talked about basically end up assigning a score to each data point. right? Like here, the score for this data point is say two because you have to go down two levels of the tree to isolate it. Whereas the score for this data point here might be like four or something like that similar thing with the Z-score and uh, even this thing. you have to choose a parameter for how many multiples of the interquartile range you want to consider as your in-distribution data. So however, with all these methods, you end up with scores for your data points. and then in order to decide what are outliers, you have to choose a cutoff. You have to choose a threshold, and we'll in a moment talk about how you can go about doing that. One final method that I'll talk about for identifying outliers is looking at k N Distance. So if you look at your data in feature space, similar setup is the last picture. We have a bunch of data points, a bunch of other data points, and some things that might be more like outliers. We can choose a Canon distance metric and a value for K and then what we can do is assign a score to each data point by looking at its K nearest neighbors and Computing just the average distance to those neighbors. And it's a pretty intuitive method, right? So if we look at this data point, for example, here's one of its closest neighbors, here's the second closest. here's the third closest. And so the mean distance is pretty small, right? But if we look at a data point, that's an outlier. The mean distance is going to be a lot larger. And so here you need to do some things like choose a parameter for K and choose what your distance metric is. But then once you choose those things, you have a a technique for scoring outliers. Any questions so far? Oh, actually the third method I wanted to talk about. That's actually really cool. So I will talk about that. One final technique that you see being used sometimes is uh, falls into the category of reconstruction based methods. So has anybody heard of an auto encoder? I Don't know if this is covered in 6036? Yeah, Okay, can somebody tell me what an auto encoder is? Yeah, so an autoencoder Maps A high dimensional input to a lower dimensional latent space and ideally such that the different features are disentangled and another part of the autoencoder are part of How It's trained is it can learn to map back from that latent space to the original input space. And so you can have an auto encoder that say, takes in an image like a picture of a five. So this is foreign [Music] using autoencoder. Reconstruction loss. So an auto encoder might take in an image like a five and now this is a model that transforms this into some low dimensional latent space. This part's called the encoder and then there's another part of the model that is called the decoder that can turn data in this low dimensional latent space back into data in the input space. And the idea with an auto encoder is you want to be able to take data in your distribution, turn into a slow dimensional thing, but actually be able to reconstruct what you started with. So any ideas on how we might be able to use this for detecting outliers? Yeah, it's good. Decoder has a difficult time reconstructing an image. If the result is very blurry then the image probably doesn't have the same set of features that your average image and distribution would have. Yeah, exactly. So if you feed in in distribution images to your auto encoder like encoder decoder, pair the whole thing. It's likely that what you start with and what you end up with look pretty similar. but if you feed it funny stuff that it's never seen before, it's likely that what you get out doesn't look quite as similar. Say it's like Blurry or something else is wrong with it compared to what you started with. So like say you're working with the data set that's handwritten digits like mnist. Oh, do you have a question? You did it. Of course you wouldn't know what the Clusters Yeah, so that's a great question. It's like okay, we see how this can be straightforwardly applied. Actually can I finish explaining that or drawing out the method first? Then I'll answer your question. But yeah, the question was how does this apply to outlier detection as opposed to this anomaly detection? But yeah. so sometimes we train this on handwritten digits like mnist and uh so yeah, we have things like five and you pass it through. it still looks like a five if you feed it. funny out of distribution stuff like maybe you have bad data that's a letter instead of an image, you feed in something that's like the letter I capital I and you feed it through this Auto encoder. blatant representation decoder. Wow, drawing is getting sloppy decoder and now it turns into something that looks kind of different. Maybe you get a one out or something like these look kind of similar and it's like plausible that this would happen with an auto encoder if you look at the Reconstruction loss. So you use this when training the auto encoder in the first place. Like the way these are trained is you take this whole thing you say. Okay I feed it data this thing and this thing should look similar. So you might use say L2 distance between the input and output. The L2 distance here is going to be pretty small whereas the L2 distance here or whatever you're using for a reconstruction loss is going to be larger and so you can use that to compute the score. So now going back to your question like okay we see how we can use this for anomaly detection. Like we train the auto encoder on the train set and then feed it stuff from for the new data we got and see what the Reconstruction loss is. But this can also be applied to the problem of outlier detection. Like if your data has mostly in distribution data and then some funny data, the representation that this learns will end up being such that you have lower reconstruction loss with your in distribution data compared to the out of distribution points. Yeah, that's a that's a really good question. Questions: Um, so the question is what's the difference between the encoder in an auto encoder in kernel PCA This is uh, is it okay we talk about that after the lecture. Yeah, um a little bit less related to the problem of outliers and like how you can use generative models and their reconstruction loss as a score. and so you could also do this with different generative models. but this is just one example and it's commonly used. All right. Any more questions on Outliers: Okay, so before we move on, I'll talk briefly about the lab assignment for today. So the lab assignment is entirely focused on outliers and what we've done is we've made a data set for you. It's a data set consisting of a bunch of pictures of dogs and then we. So that's our training data set. We're setting this up as an anomaly detection problem so you have what dogs look like as input data and then the goal is to yeah, given fresh data, figure out if it's uh, if it's an outlier or not and so you'll explore a variety of techniques there. We've implemented some really simple Baseline methods that work terribly for you and the we've given you some hints for how you might be able to implement something that's a little bit better. One thing that we recommend you try is use a pre-trained model to compute embeddings for those images and then use K N distance as a metric and that actually works surprisingly well on the data set used in the lab. Use a pre-trained model for computing image embeddings, right? So you start off with these high dimensional images. doing Canon distance and image space probably doesn't make that much sense and so you use, say, a pre-trained model Like you can find a pre-trained model on Imagenet or use clip or one of the other Transformer models or something like that and we have links to those as you can just take the last layer or one of the penultimate layers of the neural net and just use that as the feature. Yeah, I Don't know how much this is covered in a class like O36, but this is a super common technique. Like training models and large data sets is hard. It's super nice to be able to leverage pre-trained models and then you can do lots of cool things with them. You'll probably teach a whole class on this topic. like cool things you can do with pre-trained models and one final thing I'll just mention and you can explore this more in the lab is okay. These methods I'll give you scores. How do you actually evaluate how well the method does? So what you can do is plot how the true positivity rate like for choosing different thresholds, how the true positivity rate varies with respect to the false positivity rate. Like basically how good is your method for various thresholds. You choose how much actual outliers you identify compared to non-outliers and you can plot that and that gives you a curve. And if you so you can compare the different curves for these different methods you implement. and uh, another thing you can do if you want a single summary number is you can compute the area under that curve and then you get one number that describes how well your outlier detection or anomaly detection is working. Awesome! Any other questions, right? So one final topic we will talk about in today's lecture is distribution shift. So quick show of hands. Who's heard this term before? Distribution shift Or like covariate shift or one of those things. Okay, like a third of you or something. So this is actually [Music] This is very much a real problem that probably occurs in like every single machine learning task to varying degrees, and so it is useful to understand it. So in this part of the lecture, we'll briefly talk about what is distribution shift, classifying distribution shift, and just talking through some examples and then talking about how you can address this issue. Oh yeah, all right, does anybody happen to know the definition of distribution shift by any chance? So distribution shift occurs when the joint distribution between inputs and outputs at test time I'm sorry, yeah, that well, at train time is not equal to The Joint distribution of inputs and outputs at test time. And we'll break this down and look at different classes of this happening. But even before we dive into that, you can intuitively see why this could be problematic, right? Like, if you do machine learning on one distribution and then deploy your model in a setting where there's a different distribution, you might not expect that the model would work particularly well. right? [Music] So one type of distribution shift you might see is something called covariate shift or data shift, and that occurs when the distribution of inputs varies between train and test. Also, when I say train and test, is it clear that this is like you train a model and then you deploy the model. It's not like you're just evaluating a model where you have all the ground truth. Here, it's like You train your self-driving car on some data and then you go evaluate your self-driving car and like you don't want it to crash and kill somebody. So covariate shift is when your input distribution is mismatched between train and test. but uh, when? lots of stuff's right. So when your input distribution changes. but the relationship between inputs and outputs does not change between train and test. And so this is a lot easier to understand with a picture. So I will draw one for you. Now here we're looking at a very simple regression problem. Predict Y given X and suppose we have some training data I'm going to draw this to circles that looks like say something like this. Then we train a model on this data and the model we end up with might look something like this and it's like data is going up. Model predicts like when X goes up, y goes up. But it might be that when we actually deploy this model in production, the inputs we see in practice in the real world are a little bit different than the the inputs we've seen here. like maybe what we see in in practice and I'll draw these as X's So again, these are x's and dots or train versus test in this picture before. I've used different symbols to indicate different classes. That's that's not what's going on here. so we might have some some data here. but maybe there's extra data points at test time that actually look more like this. Maybe this came from a like. This is the function we've learned, but the true function actually looks kind of like this right? But at test time we only saw inputs here and so the model we we learned is very different than the than the true function. Does that make sense? I Think this one's pretty easy to come up with examples for. so you can think about examples for a moment while I Erase this board and then we'll talk through some foreign. Can you think of any situations in the real world where you might have different looking data at training time versus deployment time? Can you repeat that question? Sure. Yeah. so the I'll repeat it for the microphone. If you have a new search engine and you're trying to rank the or say predict something about the the questions people ask, the questions people ask at one point in time might look different than the questions people ask at a different point in time and this is an instance of a more General pattern where just the distribution of data is time varying. Any other Any other ideas for examples, you can also think of really concrete examples. Yeah sure, looking at x-ray images what you train on might be look different, might look different than what you evaluate on. So I'll try to make that a little bit more concrete or precise. Maybe you have a data set that comes from a particular type of x-ray machine, like a particular brand and scenario Input data distribution has a present and it quirks of that particular x-ray machine. So maybe this is you like train on a data set that came out of MGH and they have a particular brand of X-ray and then you go to deploy this in hospitals all across the world and everybody uses different x-ray machines and those quirks are going to be different for those different x-ray machines. And so now this yeah distribution mismatch between your input and output. All right, foreign. Let's try to go for one more any other ideas. Was that a hand? Yeah, so the question is, what's the uniqueness or like? What's the difference between covariate shift and just distribution shift in general? So again, it's in particular looking at situations where the relationship between inputs and outputs doesn't change, but the distribution of inputs does. Um and so uh, I can try to come up with an example that's more clear. Um and also in the same example, I'll just give you another example of covariate shift [Music] if you have a self-driving car and it's trained on the sunny sunny Streets of San Francisco so all the data it seems like Sunny streets, no bad weather and then you go and deploy it in Boston On a snowy day like today, you could imagine that you might have some problems, right? And the reason this is covariate shift and there's no change in the relationship between inputs and outputs is like the way you should be driving given some particular conditions Outside doesn't change right? Like you drive a certain way in the snow, you drive a certain way in dry weather. It's just that your training data didn't have any snowy driving conditions, but at evaluation time you have to deal with them. But yeah it's These Can be a little bit confusing because oftentimes you well you can have both or you can have like distribution shift. In general that's not like just uh, covariate shift and we'll get into that yeah, like present relationship right? But and it's like always there, right? but then sort of like for example, the way that we measure it changes a little bit. Yeah yeah. okay so we're collecting more and varied data during training time. Resolve covariation. Yeah yeah so the yeah, it's like we're collecting more and Vary data during training time. Resolve this problem. and like the answer is yeah, like that's a very common way of addressing it. In certain situations, you can get around the issue without collecting more data, but that can be a little bit tricky. Yeah, so like you're self-driving car once you train it in San Francisco like maybe get some data from Snowy roads as well and then it'll probably do better. Any other questions. So one other type of shift I'll talk about in this lecture is something called concept shift and just given what we've been talking through so far, can anybody guess what this means or what is to find us? Yeah, yeah, exactly. It's when your probability of Y given X is different at train time versus test time [Music] And I'll add in the last part. so the relationship between inputs and outputs actually changes between train and test time. but the distribution of inputs themselves does not change. so this one's a little bit less intuitive. or at least I find it less intuitive. and it's also something that's actually harder to deal with in practice. So to get a some intuition for how this is or what how this works, I will draw another picture. So suppose we have some data here. In this example, we're going to have a two class classification setting. so these are two feature axes and I'm going to draw the different classes as pluses and minuses. So say we have some positive data here and some negative data here and then this might be the boundary between them and this is the situation at training time. but what if at testing time this boundary actually changes like all the data. Okay, so I'm not touching any of the data. points, they're staying in the same space. But maybe this boundary like looks like this now and these all become positives at test time. So right, P of X hasn't changed I haven't moved any of the input data points. It's actually the exact same distribution. but I've changed the relationship between input and output because now these things are positive when they were negative before. So I found it a little bit tricky to come up with examples for this, but let's try to I have a couple in the lecture notes and we can try to talk through it together. [Applause] Um, I Think Oftentimes you have situations where there is concept shift, but also like it's really hard to find situations where the input data distribution does not change at all between train and test. So the examples I came up with do have some covariate shift as well. Yeah, while I'm erasing the sport you can think about if you can come up with any examples of concept shift Foreign. So again, this is where the relationship between inputs and outputs changes at training time versus test time. Yeah. So for example, if we change the labels of some class, yeah, Can anybody come up with any more concrete examples? Yeah, Okay, so yeah. yeah. So this is another kind of funny time varying thing. but rather than a Time varying input distribution, it's a Time varying change in the relationship between input and output. So we might have as our inputs X Or the yeah. The inputs might be just songs themselves. raw songs and the songs themselves don't change over time like the song is the song. But it might be the case that people rate the songs differently in 1980 versus 2023 our own smoke, we're thinking like we literally yeah, um. Also, it's it's like at test time we actually don't. We don't have the labels, right? It's just like what does the model end up doing and it's deployed? Or in the real world, it's not overlapping. Yeah, okay, so maybe at training time we have. We're careful to not collect examples where they're overlapping classes, but at evaluation time we might have samples which belong to multiple classes. I Think that's an example of covariate shift, right? It's like, maybe you know, say, a data set like image Network Careful to only collect a a baseball or a baseball glove. But and so the model's only seen those things at training time. But at deployment time there are a lot of pictures of baseballs in baseball gloves. so the input distribution is changing there, right? Or I Got an example. So like there is like an app that ever do some stuff like this right decided to hit this one. So everybody that everybody loved Yeah, sure. So I'll repeat that for the microphone. Maybe you're predicting the popularity of celebrities based on some some features and it might be the case that some celebrity does something unreasonable and now people don't like them anymore. And so maybe the input data that you're using to predict the celebrity's popularity itself hasn't changed. But the way people think about the celebrity has changed. And I'll give one final example. Uh, one that I like and this is like a super real world example. Um, this is related to stock prices, so you know lots of people train Financial machine learning models right? It's a popular thing to do and one thing you might try to do is predict a company's stock price based on some fundamentals about the company, right? So like companies have various statistics that you can look at. like how much they like how much they profit every year, how much revenue they have every year. So one particular thing you might look at and one thing a lot of investors look at is something called the earnings per share, right? Like the company makes a certain amount of money, there are certain number of shares that have been issued. How many dollars does the company make in earnings per share, right? That's like one reasonable metric for measuring the health of the company. And so our X might be our earnings per share and for why? We might look at the stock price and we're trying to maybe have some other features. But yeah, let's say simple setting. We're trying to predict stock price based on earnings per share. What's kind of interesting? So this ratio this x to y or like earnings per share over stock price is something called the P E ratio the price to earnings ratio. It's a number that a lot of people look at and what's kind of interesting is that this has changed over time. So like for example, I looked this up for the S P 500 companies in 1975. So in 1975 this was uh 8.3 and in 2023 this is like about 20.. So the relationship between X and Y has actually gone up like the way people value a company like companies are a lot more highly valued now for making the same amount of money compared to like whatever. 30 years ago, 40 years ago, this is A and yeah, it's probably the case that earnings per share over all the companies has also changed over time, right? Like companies change like things have changed a lot since 1975.. But this relationship itself has also changed. And so I think this is a pretty clear example of concept shift. So yeah, these things happen in the real world. What do you do about them I Think we had one suggestion already, which is oh, when you notice this happening, maybe you try to figure out um, so you have covariate shift and you're trying to figure out okay, like what input data do I have at test time that I'm missing. At training time, you can go out and collect more data. But before we talk about addressing distribution shift, let's look at some ways of detecting it. Does anybody have any ideas? So again, the setting here is like you train a machine learning model on some data and then you've gone and deployed it in the real world. It's not like you have a test set on your laptop and you actually have the ground truth of the labels. Yeah, yeah yeah. so you can apply anomaly detection. You can look at the distribution of your so this is particularly useful for seeing. If you have covariate shift at deployment time, you can take the data you had a training time and like train an anomaly detector on it and then apply that at inference time you can see like okay, is this data point anomalous and then you might be able to yeah, you'll have to figure out how to handle that action. Like maybe you don't trust the output of your model as much if you think the data point is an anomaly or something like that. But yeah, more generally one thing you can do and you can look in the lecture notes for specific examples of this. but one thing you can do is monitor your the data itself at deployment like in your deployment setting. And yeah, apply things like anomaly detection to see if there's been distribution shift. Can anybody figure out what word I'm going to write Here You can monitor your data, or you can monitor your model. Yeah, yeah. so especially if you can find good metrics for model performance. Um, you can also look at those at deployment time, keep a close eye on them, and see how they change over time. So going back to some of the early Um examples we talked about in this lecture like fraud detection. There's like some really great metrics there that you could look at at runtime, right at deployment time, right? Like you could just look at how many dollars you lose per day to fraud and like if that's going up by a lot, like something is wrong and you need to address it right. Or like self-driving cars. if your cars start crashing a lot more something needs to be done. Um, and there are a variety of metrics you could look at for your model. And then as far as uh, addressing distribution shift, this is a kind of advanced topic. We won't go too much into detail there, but yeah, one of the things that was proposed was. once we notice this is a problem, we can collect more data and then retrain our model to address the shift. So it's that's uh, one one approach you can use. All right? So that's All I have to say on distribution shift. So that is it for today's lecture. Um, if there are any final questions, I'm happy to answer them now. otherwise I will or we will see you tomorrow for a lecture on Active Learning Well.</div></div></div></div></div></div><div contenteditable="false" data-content-editable-void="true" style="width: 0px;"><div style="display: none; flex-shrink: 0; pointer-events: none; width: 0px; position: absolute; right: 192px; opacity: 0;"><div style="display: flex; flex-direction: column; padding: 5px 16px; width: 340px; flex-shrink: 0; height: 100%; position: relative; pointer-events: none; z-index: 1;"><div style="position: absolute; pointer-events: none; width: 100%; height: 100%; top: -5px; background: linear-gradient(white 0px, rgba(255, 255, 255, 0) 15px);"></div></div></div></div></main><span style="height: 1px; width: 1px;"></span></div><div class="notion-presence-container" style="position: absolute; top: 0px; left: 0px; z-index: 89;"><div></div></div></div></div></div><div class="notion-peek-renderer" style="position: fixed; top: 0px; right: 0px; bottom: 0px; width: 960px; z-index: 109; transform: translateX(960px) translateZ(0px);"></div></div></div></div></div><textarea aria-hidden="true" style="opacity: 0; pointer-events: none; position: fixed; left: 0px; top: 0px;"></textarea><textarea aria-hidden="true" style="opacity: 0; pointer-events: none; position: fixed; left: 0px; top: 0px;"></textarea><script src="assets/js/1172e9111a5fb396bcb8a05870b5eabf8abf221c.js" type="text/javascript"></script><div style="width: env(safe-area-inset-bottom);"></div></body></html>