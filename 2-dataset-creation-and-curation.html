<html class="notion-html"><head lang="en"><meta charset="utf-8"/><meta content="width=device-width,height=device-height,initial-scale=1,maximum-scale=1,user-scalable=no,viewport-fit=cover" name="viewport"/><title>6. Dataset Creation and Curation</title><meta content="en_US" property="og:locale"/><link href="data:image/png;base64,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" rel="shortcut icon" type="image/x-icon"/><link href="/images/logo-ios.png" rel="apple-touch-icon"/><meta content="yes" name="apple-mobile-web-app-capable"/><meta content="telephone=no" name="format-detection"/><meta content="no" name="msapplication-tap-highlight"/><link href="assets/css/e218a1aef6df86309cb95b61e446888efa3b0379.css" media="print" rel="stylesheet"/><link href="assets/css/e7df85b6a5b33bc52629df6d3bd37d197c7a873d.css" rel="stylesheet"/><meta content="Edouard d'Archimbaud" name="title"/><meta content="Edouard d'Archimbaud official website" name="description"/><link href="assets/css/e1d809d762eeca23edf0cb31bb17bf3c703085f5.css" rel="stylesheet"/><style type="text/css"></style></head><body class="notion-body"><style>body{background:#fff}body.dark{background:#191919}@keyframes startup-shimmer-animation{0%{transform:translateX(-100%) translateZ(0)}100%{transform:translateX(100%) translateZ(0)}}@keyframes startup-shimmer-fade-in{0%{opacity:0}100%{opacity:1}}@keyframes startup-spinner-rotate{0%{transform:rotate(0) translateZ(0)}100%{transform:rotate(360deg) translateZ(0)}}#initial-loading-spinner{position:fixed;height:100vh;width:100vw;z-index:-1;display:none;align-items:center;justify-content:center;opacity:.5}#initial-loading-spinner svg{height:24px;width:24px;animation:startup-spinner-rotate 1s linear infinite;transform-origin:center center;pointer-events:none}#skeleton{background:#fff;position:fixed;height:100vh;width:100vw;z-index:-1;display:none;overflow:hidden}#initial-loading-spinner.show,#skeleton.show{display:flex}body.dark #skeleton{background:#191919}.notion-front-page #skeleton,.notion-mobile #skeleton{display:none}#skeleton-sidebar{background-color:#fbfbfa;box-shadow:inset -1px 0 0 0 rgba(0,0,0,.025);display:flex;width:240px;flex-direction:column;padding:12px 14px;overflow:hidden}body.dark #skeleton-sidebar{background-color:#202020;box-shadow:inset -1px 0 0 0 rgba(255,255,255,.05)}#skeleton.isElectron #skeleton-sidebar{padding-top:46px}#skeleton .row{display:flex;margin-bottom:8px;align-items:center}#skeleton .row.fadein{animation:1s ease-in 0s 1 normal both running startup-shimmer-fade-in}#skeleton .chevron{width:12px;height:12px;display:block;margin-right:4px;fill:rgba(227,226,224,.5)}body.dark #skeleton .chevron{fill:#2f2f2f}.startup-shimmer{background:rgba(227,226,224,.5);overflow:hidden;position:relative}body.dark .startup-shimmer{background:#2f2f2f}.startup-shimmer::before{content:"";position:absolute;height:100%;width:100%;z-index:1;animation:1s linear infinite startup-shimmer-animation;background:linear-gradient(90deg,transparent 0,rgba(255,255,255,.4) 50%,transparent 100%)}body.dark .startup-shimmer::before{background:linear-gradient(90deg,transparent 0,rgba(86,86,86,.4) 50%,transparent 100%)}#skeleton .icon{width:20px;height:20px;border-radius:4px}#skeleton .text{height:10px;border-radius:10px}#skeleton .draggable{-webkit-app-region:drag;position:absolute;top:0;left:0;width:100%;height:36px;display:none}#skeleton.isElectron .draggable{display:block}</style><style id="scroll-properties"></style><div id="notion-app"><div class="notion-app-inner notion-light-theme" style='color: rgb(55, 53, 47); fill: currentcolor; line-height: 1.5; font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; -webkit-font-smoothing: auto; background-color: white;'><div style="height: 100%;"><div class="notion-cursor-listener" style="width: 100vw; height: 100%; position: relative; display: flex; flex: 1 1 0%; background: white; cursor: text;"><div class="" style="display: flex; flex-direction: column; width: 100%; overflow: hidden;"><div style="max-width: 100vw; z-index: 100; background: white; user-select: none;"><div class="notion-topbar" style="width: 100%; max-width: 100vw; height: 45px; opacity: 1; transition: opacity 700ms ease 0s, color 700ms ease 0s; position: relative;"><div style="display: flex; justify-content: space-between; align-items: center; overflow: hidden; height: 45px; padding-left: 12px; padding-right: 10px;"><div class="notranslate" style="display: flex; align-items: center; line-height: 1.2; font-size: 14px; height: 100%; flex-grow: 0; margin-right: 8px; min-width: 0px;"><div class="notion-selectable notion-page-block" data-block-id="d8397a78-1321-456c-9c10-1feea7a42b60" style="display: flex; align-items: center; min-width: 0px;"><a href="edouard-d-archimbaud.html" rel="noopener noreferrer" style="display: flex; text-decoration: none; user-select: none; cursor: pointer; color: inherit; min-width: 0px;"><div role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: inline-flex; align-items: center; flex-shrink: 1; white-space: nowrap; height: 24px; border-radius: 4px; font-size: inherit; line-height: 1.2; min-width: 0px; padding: 2px; color: rgb(55, 53, 47);" tabindex="0"><div style="display: flex; align-items: center; min-width: 0px;"><div class="notion-record-icon notranslate" style="display: flex; align-items: center; justify-content: center; height: 20px; width: 20px; border-radius: 0.25em; flex-shrink: 0; margin-right: 6px; font-weight: 500;"><div style="display: flex; align-items: center; justify-content: center; height: 20px; width: 20px;"><div style="height: 18px; width: 18px; font-size: 18px; line-height: 1; margin-left: 0px; color: black;"><span aria-label="üë®‚Äçüíª" role="img" style='font-family: "Apple Color Emoji", "Segoe UI Emoji", NotoColorEmoji, "Noto Color Emoji", "Segoe UI Symbol", "Android Emoji", EmojiSymbols; line-height: 1em; white-space: nowrap;'>üë®‚Äçüíª</span></div></div></div><div class="notranslate" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; max-width: 160px;">Edouard d‚ÄôArchimbaud</div></div></div></a></div><span style="margin-left: 2px; margin-right: 2px; color: rgba(55, 53, 47, 0.5);">/</span><div class="notion-selectable notion-page-block" data-block-id="bb024d08-b3b1-4dbd-bafc-0fa8d6a316c2" style="display: flex; align-items: center; min-width: 0px;"><a href="data-centric-ai.html" rel="noopener noreferrer" style="display: flex; text-decoration: none; user-select: none; cursor: pointer; color: inherit; min-width: 0px;"><div role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: inline-flex; align-items: center; flex-shrink: 1; white-space: nowrap; height: 24px; border-radius: 4px; font-size: inherit; line-height: 1.2; min-width: 0px; padding: 2px; color: rgb(55, 53, 47);" tabindex="0"><div style="display: flex; align-items: center; min-width: 0px;"><div class="notion-record-icon notranslate" style="display: flex; align-items: center; justify-content: center; height: 20px; width: 20px; border-radius: 0.25em; flex-shrink: 0; margin-right: 6px; font-weight: 500;"><div style="display: flex; align-items: center; justify-content: center; height: 20px; width: 20px;"><div style="height: 18px; width: 18px; font-size: 18px; line-height: 1; margin-left: 0px; color: black;"><span aria-label="üéØ" role="img" style='font-family: "Apple Color Emoji", "Segoe UI Emoji", NotoColorEmoji, "Noto Color Emoji", "Segoe UI Symbol", "Android Emoji", EmojiSymbols; line-height: 1em; white-space: nowrap;'>üéØ</span></div></div></div><div class="notranslate" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; max-width: 160px;">Data-centric AI</div></div></div></a></div><span style="margin-left: 2px; margin-right: 2px; color: rgba(55, 53, 47, 0.5);">/</span><div role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: inline-flex; align-items: center; flex-shrink: 1; white-space: nowrap; height: 24px; border-radius: 4px; font-size: 14px; line-height: 1.2; min-width: 0px; padding-left: 6px; padding-right: 6px; color: rgb(55, 53, 47);" tabindex="0"><div class="notion-record-icon notranslate" style="display: flex; align-items: center; justify-content: center; height: 20px; width: 20px; border-radius: 0.25em; flex-shrink: 0; margin-right: 6px;"><div style="display: flex; align-items: center; justify-content: center; height: 20px; width: 20px;"><div style="height: 18px; width: 18px; font-size: 18px; line-height: 1; margin-left: 0px; color: black;"><span aria-label="üéì" role="img" style='font-family: "Apple Color Emoji", "Segoe UI Emoji", NotoColorEmoji, "Noto Color Emoji", "Segoe UI Symbol", "Android Emoji", EmojiSymbols; line-height: 1em; white-space: nowrap;'>üéì</span></div></div></div><div class="notranslate" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; max-width: 240px;">6. Dataset Creation and Curation</div></div></div><div style="flex-grow: 1; flex-shrink: 1;"></div><div role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: inline-flex; align-items: center; flex-shrink: 0; white-space: nowrap; height: 28px; border-radius: 4px; font-size: 14px; line-height: 1.2; min-width: 0px; padding-left: 8px; padding-right: 8px; color: rgb(55, 53, 47);" tabindex="0"><svg class="searchNew" style="width: 14px; height: 14px; display: block; fill: inherit; flex-shrink: 0; backface-visibility: hidden; margin-right: 6px;" viewBox="0 0 17 17"><path d="M6.78027 13.6729C8.24805 13.6729 9.60156 13.1982 10.709 12.4072L14.875 16.5732C15.0684 16.7666 15.3232 16.8633 15.5957 16.8633C16.167 16.8633 16.5713 16.4238 16.5713 15.8613C16.5713 15.5977 16.4834 15.3516 16.29 15.1582L12.1504 11.0098C13.0205 9.86719 13.5391 8.45215 13.5391 6.91406C13.5391 3.19629 10.498 0.155273 6.78027 0.155273C3.0625 0.155273 0.0214844 3.19629 0.0214844 6.91406C0.0214844 10.6318 3.0625 13.6729 6.78027 13.6729ZM6.78027 12.2139C3.87988 12.2139 1.48047 9.81445 1.48047 6.91406C1.48047 4.01367 3.87988 1.61426 6.78027 1.61426C9.68066 1.61426 12.0801 4.01367 12.0801 6.91406C12.0801 9.81445 9.68066 12.2139 6.78027 12.2139Z"></path></svg>Search</div><div role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: inline-flex; align-items: center; flex-shrink: 0; white-space: nowrap; height: 28px; border-radius: 4px; font-size: 14px; line-height: 1.2; min-width: 0px; padding-left: 8px; padding-right: 8px; color: rgb(55, 53, 47);" tabindex="0">Duplicate</div><div role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: flex; align-items: center; justify-content: center; width: 32px; height: 28px; border-radius: 3px;" tabindex="0"><svg class="dots" style="width: 18px; height: 18px; display: block; fill: inherit; flex-shrink: 0; backface-visibility: hidden;" viewBox="0 0 13 3"><g><path d="M3,1.5A1.5,1.5,0,1,1,1.5,0,1.5,1.5,0,0,1,3,1.5Z"></path><path d="M8,1.5A1.5,1.5,0,1,1,6.5,0,1.5,1.5,0,0,1,8,1.5Z"></path><path d="M13,1.5A1.5,1.5,0,1,1,11.5,0,1.5,1.5,0,0,1,13,1.5Z"></path></g></svg></div><div style="flex: 0 0 auto; width: 1px; height: 16px; margin-left: 8px; margin-right: 8px; background: rgba(55, 53, 47, 0.16);"></div><div role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: inline-flex; align-items: center; flex-shrink: 0; white-space: nowrap; height: 28px; border-radius: 4px; font-size: 14px; line-height: 1.2; min-width: 0px; padding-left: 8px; padding-right: 8px; color: rgb(55, 53, 47);" tabindex="0"><svg class="notionLogo" style="width: 18px; height: 18px; display: block; fill: inherit; flex-shrink: 0; backface-visibility: hidden; margin-right: 6px;" viewBox="0 0 120 126"><path d="M 20.6927 21.9315C 24.5836 25.0924 26.0432 24.8512 33.3492 24.3638L 102.228 20.2279C 103.689 20.2279 102.474 18.7705 101.987 18.5283L 90.5477 10.2586C 88.3558 8.55699 85.4356 6.60818 79.8387 7.09563L 13.1433 11.9602C 10.711 12.2014 10.2251 13.4175 11.1939 14.3924L 20.6927 21.9315ZM 24.8281 37.9835L 24.8281 110.456C 24.8281 114.351 26.7745 115.808 31.1553 115.567L 106.853 111.187C 111.236 110.946 111.724 108.267 111.724 105.103L 111.724 33.1169C 111.724 29.958 110.509 28.2544 107.826 28.4976L 28.721 33.1169C 25.8018 33.3622 24.8281 34.8225 24.8281 37.9835ZM 99.5567 41.8711C 100.042 44.0622 99.5567 46.2512 97.3618 46.4974L 93.7143 47.2241L 93.7143 100.728C 90.5477 102.43 87.6275 103.403 85.1942 103.403C 81.2983 103.403 80.3226 102.186 77.4044 98.54L 53.5471 61.087L 53.5471 97.3239L 61.0964 99.0275C 61.0964 99.0275 61.0964 103.403 55.0057 103.403L 38.2148 104.377C 37.727 103.403 38.2148 100.973 39.9179 100.486L 44.2996 99.2717L 44.2996 51.36L 38.2158 50.8725C 37.728 48.6815 38.9431 45.5225 42.3532 45.2773L 60.3661 44.0631L 85.1942 82.0036L 85.1942 48.4402L 78.864 47.7136C 78.3781 45.0351 80.3226 43.0902 82.7569 42.849L 99.5567 41.8711ZM 7.5434 5.39404L 76.9175 0.285276C 85.4366 -0.445402 87.6285 0.0440428 92.983 3.93368L 115.128 19.4982C 118.782 22.1747 120 22.9034 120 25.8211L 120 111.187C 120 116.537 118.051 119.701 111.237 120.185L 30.6734 125.05C 25.5584 125.294 23.124 124.565 20.4453 121.158L 4.13735 99.9994C 1.21516 96.1048 0 93.191 0 89.7819L 0 13.903C 0 9.5279 1.94945 5.8785 7.5434 5.39404Z"></path></svg>Try Notion</div></div></div><div style="width: calc(100% - 0px); user-select: none;"></div></div><div class="notion-frame" style="flex-grow: 0; flex-shrink: 1; display: flex; flex-direction: column; background: white; z-index: 1; height: calc(100vh - 45px); max-height: 100%; position: relative; width: 1920px;"><div class="notion-scroller vertical" style="display: flex; flex-direction: column; z-index: 1; flex-grow: 1; position: relative; align-items: center; margin-right: 0px; margin-bottom: 0px; overflow: hidden auto;"><div style="position: absolute; top: 0px; left: 0px;"><div></div></div><div class="whenContentEditable" data-content-editable-root="true" style="caret-color: rgb(55, 53, 47); width: 100%; display: flex; flex-direction: column; position: relative; align-items: center; flex-grow: 1; --whenContentEditable--WebkitUserModify:read-write-plaintext-only;"><span style="height: 1px; width: 1px;"></span><div class="pseudoSelection" contenteditable="false" data-content-editable-void="true" style="user-select: none; --pseudoSelection--background:transparent; width: 100%; display: flex; flex-direction: column; align-items: center; flex-shrink: 0; flex-grow: 0; z-index: 2;"></div><div style="width: 100%; display: flex; justify-content: center; z-index: 3; flex-shrink: 0;"><div style="max-width: 100%; min-width: 0px; width: 900px;"><div style="width: 100%; display: flex; flex-direction: column; align-items: center; flex-shrink: 0; flex-grow: 0;"><div style="max-width: 100%; padding-left: calc(96px + env(safe-area-inset-left)); width: 100%;"><div class="pseudoSelection" contenteditable="false" data-content-editable-void="true" style="user-select: none; --pseudoSelection--background:transparent; pointer-events: none;"><div class="notion-record-icon notranslate" style="display: flex; align-items: center; justify-content: center; height: 78px; width: 78px; border-radius: 0.25em; flex-shrink: 0; position: relative; z-index: 1; margin-left: 3px; margin-bottom: 0px; margin-top: 96px; pointer-events: auto;"><div style="display: flex; align-items: center; justify-content: center; height: 78px; width: 78px;"><div style="height: 78px; width: 78px; font-size: 78px; line-height: 1; margin-left: 0px; color: black;"><span aria-label="üéì" role="img" style='font-family: "Apple Color Emoji", "Segoe UI Emoji", NotoColorEmoji, "Noto Color Emoji", "Segoe UI Symbol", "Android Emoji", EmojiSymbols; line-height: 1em; white-space: nowrap;'>üéì</span></div></div></div><div class="notion-page-controls" style='display: flex; justify-content: flex-start; flex-wrap: wrap; margin-top: 8px; margin-bottom: 4px; margin-left: -1px; color: rgba(55, 53, 47, 0.5); font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; height: 24px; pointer-events: auto;'></div></div><div style="padding-right: calc(96px + env(safe-area-inset-right));"><div><div class="notion-selectable notion-page-block" data-block-id="1607542f-c063-4fb5-abfd-d1d07f810c87" style='color: rgb(55, 53, 47); font-weight: 700; line-height: 1.2; font-size: 40px; font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; cursor: text; display: flex; align-items: center;'><div contenteditable="false" data-content-editable-leaf="true" placeholder="Untitled" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">6. Dataset Creation and Curation</div></div><div style="margin-left: 4px;"></div></div></div></div></div><div style="width: 100%; display: flex; flex-direction: column; align-items: center; flex-shrink: 0; flex-grow: 0;"><div contenteditable="false" data-content-editable-void="true" style="padding-left: calc(96px + env(safe-area-inset-left)); padding-right: calc(96px + env(safe-area-inset-right)); max-width: 100%; width: 100%;"></div></div></div></div><main style="display: flex; width: 100%; justify-content: center; padding-top: 5px;"><div style="max-width: 100%; min-width: 0px; width: 900px;"><div class="notion-page-content" style="flex-shrink: 0; flex-grow: 1; max-width: 100%; display: flex; align-items: flex-start; flex-direction: column; font-size: 16px; line-height: 1.5; width: 100%; z-index: 4; padding-bottom: 30vh; padding-left: calc(96px + env(safe-area-inset-left)); padding-right: calc(96px + env(safe-area-inset-right));"><div class="notion-selectable notion-text-block" data-block-id="92d3f980-3342-42b7-a639-9d96b8eff12f" style="width: 100%; max-width: 1728px; margin-top: 2px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; min-height: 1em; color: rgb(55, 53, 47); -webkit-text-fill-color: rgba(55, 53, 47, 0.5);"></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="a007238b-c2f5-4393-a298-5845f50f2938" style="width: 100%; max-width: 1728px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; min-height: 1em; color: rgb(55, 53, 47); -webkit-text-fill-color: rgba(55, 53, 47, 0.5);"></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="1c496f78-35ac-49e0-ae14-245885037cb7" style="width: 100%; max-width: 1728px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; min-height: 1em; color: rgb(55, 53, 47); -webkit-text-fill-color: rgba(55, 53, 47, 0.5);"></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="af0e5324-3081-4300-989f-3efd0cd4db45" style="width: 100%; max-width: 1728px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;"><a class="notion-link-token notion-enable-hover" data-token-index="0" href="https://www.youtube.com/watch?v=R9CHc1acGtk&amp;t=18s&amp;ab_channel=IntroductiontoData-CentricAI" rel="noopener noreferrer" style="cursor:pointer;color:inherit;word-wrap:break-word;text-decoration:inherit" target="_blank"><span class="link-annotation-af0e5324-3081-4300-989f-3efd0cd4db45--208205223" style="border-bottom:0.05em solid;border-color:rgba(55,53,47,0.4);opacity:0.7">https://www.youtube.com/watch?v=R9CHc1acGtk&amp;t=18s&amp;ab_channel=IntroductiontoData-CentricAI</span></a></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="b28d47a9-4c1e-45ac-9df0-8a090063cacb" style="width: 100%; max-width: 1728px; margin-top: 1px; margin-bottom: 0px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">Uh hi guys, welcome back. Uh, this lecture will be mostly taught by Jonas I'll just be doing the first five minutes or so. Um, and we're gonna talk about data set, curation and creation. So how do you make a data set in such a way that you can train the model that you want to train? Uh, better than you know If you've made the data set a different way, so are we all on board with what we're going to talk about? We're making data sets and how do you choose aspects of the data set to make it in a certain way That will make your model better? So that's the focus. Cool, All right. So I I Want to just remind us of this counts Matrix We saw yesterday. So this is that joint distribution called The Confident Joint. But it's just an unnormalized joint distribution. And can somebody tell me what this 32 would mean in this data set? Like, how would you interpret that 32? Okay, yeah, there are 32 images that are labeled cow that are actually gone. Yeah, Estimated. Yeah, so there's 32 images that are labeled cow. but they're actually pictures of dogs. Or if this is text, there's 32. You know, text examples about dogs, but they're actually they're mistakenly labeled as cow And so whatever. The data set is. For these three classes, we've got 32 examples that we've estimated are their label given as cow, but like they probably should have been labeled dog? Okay, so that's what this thing is and then we can normalize that and we can get this joint distribution. So we saw that earlier. With this in mind I Want to just look at two motivating examples for data set, curation and creation. So imagine that Instead, you had this Matrix here. Uh, just as like an example. So this is the same. You got your noisy labels and your classes. Now you don't have any information. you're a machine, so they're just numbers to you. One, two, three, four, five. Um, and then you guys can see that all the off diagonals are zero except for two The 50s right here. Okay, so the big takeaway. The thing to try to figure out right now is uh, how would you take this data set and try to make it better so you can train a better machine learning model? And yeah, [Music] And then you remove the PC over 215. Yeah, that's a great approach. So just repeating for the mic and for the recording. but just repeating so you would take you know these 50 examples here. These are things that were labeled a four, but we think there are three and you would also take these 50 things here that were labeled a three. But we think there are four and you combine them and you have these hundred things and you can get them just by sorting your data that's labeled that we think is uh or that first. Remember the first method Where you are, you're automatically finding things that are, on the off diagonal. Let's just use that one for Simplicity So we already know what these 50 things are and then we could remove them from the data set. Or we could look at them by hand or using some other tool and we could relabel them and correct their label. So that would be one way to improve the model. Can anybody think of another way that's very different than what we talked about yesterday and that has a lot to do with data set curation. [Music] Yeah, I Like it. So finding some kind of overlapping feature and using that to make better guesses of the label? something like that. [Music] Yeah, totally. So this is an approach actually called labeling functions and you can use that to get weak and noisy labels. You could take that approach. What about something that you could do to the data set though at a higher level. So instead of working with individual examples, Is there anything you could think that you could do with the classes themselves? Yeah, it's not confusing. Almost anything else. Yeah, you could try that, right? And unlike in school where you sort of have a data set and you have to predict three or four like this is your model. You know, like you're in control like this is in the real world, this is your data set if you want to predict a new class that's called three four, you could totally do that instead. So now you can have four classes and your machine learning model just predicts four classes instead of five. And then once it's predict one of these classes, you could have some second model that maybe tries to discriminate between the two. There's lots of things you could do, but you can see now if if you have this data set and you've merged these two classes together, you would have actually no issues in your data, but you didn't have to correct any examples. So you fixed things at the data set level and how you create the data set versus fixing them at the example level. And so that's what we're shifting to in this lecture is thinking about how do we change the data set. So that's one thing we can do. Two more quick things if we change this 50 to a uh, a 20 I Just want to make sure we understand what's what this means. So can someone tell me the difference between this one being a 50 and this one being a 20. Hired to indicate yeah, totally Totally. Yeah. So it's a different rate of of error in in each Direction And that's why we want to use something like what we saw yesterday versus using just like a correlations Matrix So you could totally just do the correlation of every pair of classes. You could have done that, but correlate that would be symmetric because correlation is symmetric. So this is more informative than doing a correlations Matrix I Just want to make sure we got that idea. And then another idea is to keep in mind is that this means that for example, if you have a four, it's more likely to be mislabeled a three. And when might that happen is when you have a is a relationship and I'll show you an example of that. So for example, like a missile is a projectile and so it's more. Or for example, someone from California is from United States It's much more likely that someone from California is mislabeled as being in the U.S than someone from the US being mislabeled as California because there's 50 states. So you see like when something is A, you often have this happen. So that's one key idea. Okay, another one is. say that you have this is the frequency of your classes. All right. This is another data set curation trick and this is usually just called a clutter class. and you'll see this in some data sets if you have a bunch of so you've got four classes here and they have a lot of data in them and then you've got like I don't know how many, seven, eight, nine other classes that have just a little bit of data. So you can totally train a model and try to do really well on all of them. or what. some people do. And there's some reasons why this is good. There are some cases where it's not good, but you could as an option. Just thinking from the data set curation perspective, you could join all these classes together and just make them one class. and so now you have a five class problem and call this like the Clutter class or something. And now the model just has to say I've got a lot of data. Let me distinguish what these four things are and then once I've done that, I just have to say is anything else not one of those four things So it's an easier task and the model is like the model is more likely to do an easier task well. and then if it says hey, this is clutter, you could always train another model that's like, what is this clutter? What do I think this clutter is and you could do some kind of pre-training on this and then fine-tuning whatever you want. There's a lot of approaches to do that accurately. So I just wanted to show this is we're starting to think about how do we change the data set Okay, I just have a few more slides and then I'll pass to Jonas Any questions? Yeah, one of the columns based on the roads? What would you mean again? Oh yeah, of course. Uh, would someone else like to answer that? So what does like this 12 mean Yeah. [Music] There's 12 images. [Music] Got it. So it's just 12 data points that were labeled cow, but they should have been labeled Fox Okay, Um, so I Want to show you Imagenet? We ran this on Imagenet and I just ranked the off diagonals. so those these numbers are from that previous slide and we've just sorted them in terms of what co-occurs the most and what you notice. These are actual classes in the Imagenet data set and what you'll notice is that noisy label projectile and true label missile is the most occurring pair of classes and you'll also notice that it occurs. It occurs down here again, missile and projectile. But you'll see there are more here than here because again, a missile is a projectile. so you see how that's happening. This is all data driven. There's no like human involvement here. We yeah, uh, no. these are actual counts of errors on the off diagonals and there's no normalization. So there's a data set. This is the train set so it's got like 1.3 million examples and there's 645 examples that were labeled projectile that we think might be missile. And what's really cool about this is it's all automated and so now you have all the examples that maybe you'd like to merge and you could bring them together if you for example like this is a single label data set. So imagine I showed you an image and the image is of like a missile. Okay so is that a projectile or is it a missile? Because a missile is a projectile so it's broken. It's actually a broken data set. The way this data set was created that has problems in it, there is no single label that's more true in this case just because it is a relationship. Yeah, Oh yeah. So another thing that's fun that this method reveals is that image that actually has two classes in it that are the same class. That was a mistake and this just found that automatically. So that's just a mistake in the data set and it's nice to have that pop up actually in an automated fashion. Um and you can see some more. For example, a bathtub is a tub that one's very easy and a curious is a breastplate and a chameleon is a green lizard and so forth. And so is everybody clear on how this evolves and how you can use this to say hey I Actually first of all, I'm discovering that there are issues in my data set. There are some classes that actually are other classes and maybe I would like to merge those classes, but there's definitely some problems in the way the data set is set up. if this is supposed to be single labeled classification and this automatically reveals that and then you can change your data set so that you can do better. I Would be very confused if I Was in class and someone asked me to show me a picture of a projectile or a missile and said is this a missile or is it a projectile? It's both And that's hard for a machine learning model too. And so this is just revealing that you can change the data set and then get a better model and you can see also the same thing on the Imagenet validation set like a tape player and cassette player and so forth. Um, and then I Wanted to show one final example. This just popped out from Imagenet and the question is so these are two classes that were very high up in the In in terms of co-occurring in The Confident Joint like on those off diagonals and can somebody tell me what is the difference between these two classes? Yeah, very good. Yeah. took me in a niche like an hour to figure that out. Yeah, the beauty of having a crowd of people. So for the for the microphone, the one on the left has a curved tail and it's incredible that they're so similar except for just that tiny little thing. And it's up to of course, the data set Creator and how whether the model needs to detect something so fine. But if you're for whatever the purposes of your machine learning model are, if knowing that curved tail didn't actually have any impact on the task you're trying to do, now, you have this automated approach that helps you discover these type of things and you would merge those classes and you would have a simpler task that's less confusing. Um, this is certainly confusing for me, at least. Okay with that, I'll pass it over to Jonas [Music] Just put the string pocket. Hi guys. Oh no. I still need the projector? Yeah, so yeah. So we learned about basically uh, how we might consider changing the machine learning task just now from Curtis And for the rest of the lecture, we're going to talk about actually curating the rest of the data set itself. Uh, you know. So there's the machine learning task. And then there's the data itself. And so for the rest of this lecture, we're going to focus on sourcing the data and sourcing the labels and common concerns that come up. And so one example of this is to Source labels and most machine learning data sets that have been created especially for like image classification type of tasks. they're actually labeled by multiple annotators. And how do you work with data that is labeled by multiple annotators? How do you assess the quality of their individual ratings and things like that? And if you're really interested in this subject I Highly recommend the textbook there. It goes into a lot more detail than I will. So some key questions when you're sourcing training data that you should always be asking yourself is how am I going to actually use the machine learning model and on what population will this model be making predictions and at what time those are you know, really important questions and also what kind of hypothetical edge cases can I imagine where this model might struggle and where we actually really need it to be right. Like high-stakes scenarios and rare events, these are all things you should really be thinking about at the time that you're getting the training data rather than discovering them once you've deployed the model into your application. And so, uh. One example I want to get into is here are two different images of cows. And so this is actually from a real application. and there was a model trained to predict cows. and this model was able to correctly identify that the left image contains a cow, but not the right image and so does anybody have any guesses why that might have been the case? [Applause] Yeah, exactly. So there's not many cows at the beach I Mean it's hard to verify exactly why because interpretability of models is a whole nother subject Beyond this class. but that's uh, if you go, look at the training data, you see that there is very few cows on the beach. actually zero as far as I know. And so this is an example of an issue called the spurious Correlation I Think that's it for me so we can lift the projector. we'll go over here. Yeah, so a spurious correlation is basically, um, a correlation that's present in the data that you're training your model on that does not remain in the model in the data that you're going to deploy your model on like in the real world. And so if you think about what machine learning models do, they're almost like cheaters that are looking for shortcuts. They're always trying to find what kind of pattern in the training data that you're giving me is highly correlated with the labels. It has no real knowledge about the real world, so any kind of pattern that's present and very predictive of labels the machine learning model likes to latch onto and so you need to be really careful about sort of what kind of patterns might be present in a training data set. And so asparious correlation is a special case of a broader issue in data which is called selection bias. And really, selection bias is just referring to the broader term of the training data not being fully representative of the real world or the deployment conditions. So more formally, in machine learning, you're always assuming data is coming from an underlying probability distribution. and so, uh, here you're just basically or when you have a selection bias in your data set. What it's saying is that the data distribution from which you're drawing your training data doesn't match the distribution. Uh, in the real world Deployment and this can happen for all kinds of reasons. So can anybody, uh, think of some reasons why we might have training data that has selection bias. This is also called confounding or distribution shift. Yeah, exactly. So time is like one of the most classic cases that affects sort of any time-based machine learning, where you by definition have to collect your training data in the past and then if you are going to deploy your model today, it will be making predictions in the future. And if the world is changing, there will almost inevitably be some kind of issues that are patterns that may only have been present in the past that no longer remain in the future. That's you know, a big problem in say, Finance and stock market training. Uh, can anyone else think of any other common causes of selection bias? Yeah, so if you remove too much of your data, Definitely. Um, so that you could almost imagine is like over curating the data or over, uh, filtering it because you don't want to deal with stuff that's messy. but you actually will see stuff like that in deployment. That's a problem too. Any other common causes people can think of. It's pretty difficult to collect data about what happens during a crash because it's that data. Yep, actually that's two. I'm going to break it into two. So there's rare events that, for some reason are just not. There's some mechanism that's preventing these events from making it into your training data. and then the other one was convenience based collection of training data. In a classic case of this is you are like a grad student and you're uh, doing some kind of survey and you only survey your friends because it's easy. And then one that's kind of similar to time would be location based. That's a really common one. You know, like you are doing some medical machine learning maybe And and training data comes from like three different hospitals. But actually, in the future you want to deploy these models in other hospitals and there's new kinds of distributions that are emerging there. And so the broader point is, selection bias is really, really nasty, and there's basically nothing you can do about it. and if you don't know any prior knowledge about the form that it will take, and so it's always something to be extremely extremely concerned about when you're collecting your training data and deciding what data you're going to train on. The one thing you can kind of try and do is uh, to at least evaluate if your model will suffer due to selection bias. And the way to do that is you select your validation data to be most representative of the distribution that you'll expect to see during deployment. So rather than your traditional random training validation split that you might have learned in class, you can actually think carefully about how my data might look different in the future during deployment and try and purposefully select validation data that better represents that and then remove that from the training data so the training data does not. You know, have those conditions in it and you can actually see how your model would be suffering under that sort of selection bias. And so an example of doing this for time would be you could just use the most recent data as your validation data. How about how might we do this for location? Does anybody have any ideas If there's a location-based selection bias and we actually expect there might be new locations we see during deployment. [Music] Yeah, totally. So you can just basically hold out all the data from some locations. What about for the rare events? Anybody have any idea how we could deal with trying to see how our model would do in the presence of rare events? Yeah, yeah. So the broader technique here is maybe traditionally you would be sampling the validation data uniformly at random, but you might Place higher probability on the rare event data to like over sample those for the validation set and that would actually make them even rarer in your training data, right? So then you would really see how your model is going to struggle with those. Cool. So yeah, there's uh, many other forms of selection bias that I won't get into. But just be aware that you know this in general is really, really hard to deal with. and it's something you should always be thinking about when collecting the data. So for the next topic, we'll ask the question: how much data should we collect If our goal is to achieve a particular level of accuracy, say we want to achieve like 95 accuracy, How much data do we want and to estimate this? Obviously, we have to assume we already have some data and we've you know, seen some kind of a trend, right? So here let's assume you already have your standard training data set I'll say just classification data set of sample size And and we want to estimate this question of how much data do we need from uh, data of size n One? Any ideas on how we might think about that? Yes, that's an interesting one. So one option is to use Theory I'm actually not going to write that, but yes, you can use theoretical generalization bands. That is very, very challenging for most uh, modern machine learning. They often will give you very conservative numbers. many of them. Uh, if you're if you're measuring the literal accuracy of a model, many of the generalization bounds will say the accurate or the error rate is greater than one. which is a very vacuous thing to report. So here we're going to focus actually on more empirical ways to do this. Like, practically and so a simple way you can try and think about this is to what if we train our model on a subset of the data and see how it performs and then train it on a bigger subset And so you can imagine. You have uh, training, Uh, say you have your training data here and your validation data here and this is like you know all the training ballot training data that you have. You can sub sample, say only this training data like some subset and train a first model. Then you can sub-sample a bigger data set, train a second model, and so on, and so forth. And for each of these models, you can evaluate its accuracy on the validation data right? and so that will give you sort of a and plot that looks something like this. So say we sub sample one per 10 of our training data 20 percent. Uh, you know all the way up to 80 percent, 90 and 100 percent. And so you would expect the accuracy to be much lower right at Uh 10 of the training data and then better as you've trained the model on more data and then, uh, even better on 80 of the data and on 90. even better, 100 even better. And the question now is say our goal accuracy is this number up Here we're essentially trying to figure out right at which point we will hit that goal accuracy on this X-axis What What multiplicative Factor will we need to apply to our sample size n to get there? And so uh. One problem with what I've shown so far is that each of these training runs on a subsample of the data set is pretty noisy, right? Like, especially if you're doing neural network training. It's very stochastic. It really depends on what precise subset of the data I happen to sample as my 10 of the data and so a good way to deal with that is just to do this multiple times and each time you would train another model and so you would have you know, multiple models say we do it four times for each one of these sizes you would get for for values. sort of like this again due to the stochasticity which would actually you would expect uh, stochastic stochasticity to go down right as you get higher, uh, higher fractions of your data set because things become more stable. And of course for the full data set, you can only train one model because that's all you have. Um. And then the idea is now you have all these observations of models and accuracy validation accuracies and you can actually fit a machine learning model to try and do the problem of figuring out at what n will I achieve the goal accuracy, right? So what is one remaining problem here say we fit like a linear model or a K Nearest Neighbors model. For those of you who are familiar with those to do this prediction like What makes this prediction problem a little more challenging than a traditional machine learning task? Yeah, [Music] That's yeah. a big Challenge and that's related to sort of the other challenge here, which is that we're trying to. So here's our training data. It's all between uh, zero and one, right? But our the actual Uh scenario we're interested in evaluating our machine learning model in here would be like, uh, three times the size of the training data set or something like that. So it's a huge extrapolation problem, and most you know machine learning models that you would have learned in class are not very great at extrapolation like a K Nearest Neighbors model will never extrapolate beyond the range that it's seen in its own training data. A linear model would always extrapolate linearly and fundamentally the only way to actually really do extrapolation well is to use knowledge. Um, that's just you know that there's no data when you're doing extrapolation, so you have to know something about how the world will behave as you get more data. And so this is just an empirical fact that many people have rediscovered. but roughly speaking the error rate of these models tends to behave according to the following formula. And so here these are just parameters that really depend on the application. Um, but this is the sample size and this is the error rate of the classifier on held out data after it's been trained on a data set of the sample size. And so what you can do is basically fit these two parameters to the data set that you've collected so far through your sub sampling. You know, just using a least squares type of approach. and you'll get a curve that looks something like this. and then you can just extrapolate out that curve right until it hits your goal accuracy. And if it never hits your goal accuracy, then you're in a bad shape, then you probably need to change something more fundamental about your data. Beyond Just collecting more of it. Yeah, so does that make sense? Anybody have any questions about that? Cool. Okay, the final topic we're going to talk about is, uh, the setting of labeling data. So in so far we've been talking about how much data do we need? What are the concerns that I might have when I'm collecting my data and the final remaining missing piece is where do I get my labels from? And so suppose we have a classification data set with images and some of them are like of a person and some of them are like cars. And so to label such a data set the most natural way that it's done in many applications where a human can look at the image and determine the label is to use crowdsourced workers. So for a task like this, you could just use you know any. Common Sense human could do this labeling task. These might be medical images, in which case, you might need doctors to be your annotators, but the broader idea is you would have multiple annotators. Let's denote them. A1 A2 A3 Say we have three annotators for our data set and so we just, you know, show each annotator the image that we want them to label and say the first annotator says this is a person and the second one says this is also a person and then say the Third annotator never sees this image and why might that be? They might have become an annotator in our data set later on, or we might actually be trying to save as much money as we can to get the most amount of data labeled. In which case, it's kind of redundant right to have all the annotators label every single individual example you can imagine. There are ways to use a predefined labeling budget more efficiently by only having some annotators label each example. Um, so here we might again: Ask the first annotator to provide a label for this image and they might say oh, this is our car and maybe they're the only annotator that has labeled this image and then we might have some more images. Um, another person and maybe now we don't have the first annotator label it, but we have the second annotator says this is a person and the third one says this is a car and then maybe we have another image of a car. Let's say it's a truck, but this is just a binary classification task. So this annotator say all three annotators say this is a car and so what kind of information can we start to see here? Um, one thing we can start to see is that, uh, the first annotator is doing pretty well. Right they are doing. They're giving the labels that most often seem to agree with the other annotators compared to the other two annotators. And this annotator is the one we should be most concerned about because basically, this annotator has a given an image a different label than another annotator. And so here we come to the question of, how would you know which of these annotators is giving you good labels, which one is giving you bad labels, And furthermore, how would we, uh, deal with this image where we've only got one label right from one of the annotators? That's maybe we're not. It might be challenging to say we're very confident in the label for this image and we might want to have some kind of confidence score for. if we collapse all of the annotations into a single label for each of these images, we might want to know that. maybe we're less confident about this one because it was only annotated by a single annotator. And so to introduce some notation here, we're going to denote these labels as Y I J and so this will be Uh I Here is the example and J is the annotator and these are either just empty if the annotator did not label that example, or you know, just one class if this is a classification task. Okay, what's so beyond, Uh, some of the annotators providing inaccurate labels? Can you imagine another kind of challenge that might come up with your annotators? Like, what other problems should you be thinking about Before you go, just start getting these annotators to label your data. Say you're paying each annotator for the labels they give you. like what might be scenarios that can go wrong. Yeah, so they label fast and they're not really looking at the image or thinking about it. So they're giving you a sort of lower accuracy labels, right? That's A. That's a very common case. If you do like Mechanical Turk or things like that, you often see that. Yep, Exactly. So that's a big problem. So the two problems to recap are one that you just have low low accuracy annotators. Maybe because they're just trying to do this as fast as possible and then you have, uh, copycats or collusions between annotators. Maybe one annotator actually made three accounts in your labeling platform and they're getting three times as much money that way. Um, and so the the best way to diagnose these kind of problems is to actually insert a sort of gold Standard examples randomly into the data that each annotator is labeling where you know what the true label should be, and then you can assess You know whether the annotators are agreeing with your gold standard, or whether when they're making errors from your gold standard. Are there multiple annotators that always happen to make the same kind of error? And that's really the best possible way to deal with these kind of problems. Of course, that is challenging in its own right, because it means you're now spending a chunk of your labeling budget having annotators label data that you already know the labels for. And so actually, this is unfortunately often not done in many data sets. And so for the rest of the lecture, we'll talk about in the absence of gold Standard labels that you know, each annotator has labeled a decent number of images where you're very confident you already know the true label. Sort of. How can you still try and analyze this data and pull out uh, estimates of Interest So I'll shift over here. [Applause] And so yeah, given a multi-annotator data set, Uh, what are we trying to estimate from this data? The first thing we obviously want to estimate is just like what is the consensus label for each example. So this would be the label that we think best describes this example. So going back to our example here, certainly for this image, we would. It would be quite crazy of us not to just say car is the consensus label for that image. Another thing we want to estimate is a confidence measure in these consensus labels, right? So How Likely. Is it that the consensus label is correct or not? Um, So going back to the confidence idea for this example. Intuitively, we should be a little less confident about it because there's only one uh annotator who's labeled it similarly for this image here that we have two annotators that have disagreed. So no matter what consensus label we were, we would choose for this image. We would kind of be a little cautious and not super confident that we have the correct consensus label right because we actually do have two annotators who disagree. versus in contrast to this final image here, we should be very confident that it should be labeled a car and that our consensus label probably is correct. And then finally, we would be interested in estimating a quality score for each annotator and this would be asking, uh, like, what's the overall accuracy of their labels, right? [Music] Okay, so can anyone tell me the most obvious strategy for estimating You know a single consensus label for each example over here. Like what would be your algorithm given just this data and not. Let's imagine you don't even see the images. You're just given the annotations for each example. What kind of algorithm might you use to determine what's the best label? Yeah, So the simple approach is to do majority vote And so here we're going to denote the consensus label as a Y hat I And that's going to be our best guess for the true label for example I. And so the majority vote algorithm would just count which Uh label is the most common for each example and say that is what we define Y Hat I to be what might be unnatural If we are going to use majority vote as our method for establishing consensus. What might be a natural analogy of that to estimate the confidence in the consensus? Yeah, exactly. So agreement between annotators is our score For is our confidence score for How Likely we think the consensus is correct or not. Okay, Oh, that was one. And so using some notation here, if we let j I be the set of annotators that labeled a particular example I we can mathematically write this agreement as for example I as one over the size of this set Ji And then we just sum over all the annotators that did label example I and assess whether they're given label matched our consensus label or not. And this is coming from from Majority Vote Cool. Does anybody have any questions about that? Yes, Yes. So that's a good good question. No, it does not. Right, It's not at all accounting for that. it's just looking at how much do the people that did label this example disagree? And so that's exactly a issue with this approach. One of the many issues that I will get into. And then finally, if we wanted to estimate the quality of each annotator again, doing a very simple approach like these two, how much you guys suggest estimating the quality of each annotator? Yep, so that would exactly be a very straightforward way to just estimate their quality. Um, what's one challenge that comes up? Say, we're doing this using this data set. We've established the consensus through majority vote, and now we're going to score each annotator based on how often they agree with consensus. What? What immediately jumps out as you at you as a sort of a issue? Yeah, Okay, yeah. So some annotators did not label some examples right? So we have to sort of not. like. when we're evaluating the accuracy of this annotator, we have to not consider these two examples right. What else jumps out at you? Yep, yes, that's an issue as well, because copycats are going to just, uh, be much more present in the data. And then another issue I Want to point out is, what about this example here Or trying to score this annotator where they were the only one who labeled uh, this image? They sort of get a point because you know the consensus under majority vote for this image would just be car and they're just agreeing with themselves so they really shouldn't get a point for that. Um, so that's uh, just a bit of notation. That's a subtle point I will introduce here, which is that we want to. Define Can you guys see down here? Yeah, okay, we'll Define this set I j Plus as the set of annotators who have labeled example J Let's just call it the set of J such that Y I J is not empty and there exists at least two annotators who have, uh, labeled oh no, sorry, this is yeah, going to be the set of J such that Y J is not empty and there exists another annotator J Prime who has labeled uh, the examples that this annotator has labeled. they use this original. Okay, and so with this definition in place, then we can say that we evaluate the annotator quality under the simple Baseline as the card as just the agreement between this annotator and the consensus label over those examples that fall into this set. So I'll let you digest that for a second. But really the only subtle Point here is the definition of this set is just to make sure that we're not like including when we're scoring the quality of annotator one we're not including. You know the fact that this that was the only annotator that labeled this example. So this this example would not fall into I that set. IJ Plus Okay, what's another downside of producing the uh, say consensus labels through majority vote. Yeah, so ties is another issue. Very obvious issue. That and also like just the quality of the annotators is not being accounted for right at all. Like if this is a good annotator that's a bad annotator, they sort of both get votes and they're equally weighted. So I'm going to just jump into a better method that can be used for analyzing such data. And so here. Basically, what what can we do to deal with Ties Ties are kind of challenging, right? One thing we can do is we can train a classifier on these images to do some prediction and use estimates from the classifier almost as if it was another annotator. So say we train a classifier and it you know predicts for the first image person with probability say 0.8 and for the second image it predicts car with probability zero point seven and for the third image, say person with probability 0.9 And let's say we just had trained this classifier for example, taking majority vote of all the labels initially and then training the classifier. So now that we've trained the classifier and gotten its predictions, how what? How might we break, say, the tie for this image if we are now trying to establish a consensus label? Yeah, exactly. We can you know break ties based on the classifier and why might that be a good idea? The reason it might be a good idea is because right now if we're just trying to determine what's the uh, best label just based on this information only, we're not relying on the pixels like the actual features of the example at all. But maybe the data set contains a bunch of very similar examples to this one that have much higher quality annotations. Because maybe they were labeled by many annotators and so the classifier can actually generalize you know from a similar image to this image and provide additional signal. And so using the classifier to break ties is a very easy Improvement Already on just doing majority vote solely for the reason of ties. Another thing is the classifier can help us with these nasty, singly labeled images where you just had one annotator who labeled the image. For those, you're just really relying only on that annotator, right? And so without anything else, there's not much you can do besides just take that annotator's word as your consensus label. But if your classifier say is extremely extremely confident about that example because it's seen a hundred other cars in the data set that all had the same label and they all looked very similar to this car, then maybe you say okay, this one annotator said it's car, My classifier is very confident this is a car too, And so I'm much. I'm becoming more confident in the consensus quality for this example. Foreign the final part very quickly. Um, but broadly speaking the a way we can get a better estimate of all three of these quantities is a method called Crowd Lab that you will see in your lab assignment for this week or for this lecture I should say. And the idea of this method is that we are going to form a probability distribution of what we think the clap the true class should be just like you saw in confident learning. Based on the features of the example as well as all the annotations and the way we will form this probability distribution is we will do it as a weighted average Of all our annotators, we will allow each annotator, we will convert each annotator's label to a probability distribution, almost, treating the annotator like a predictor right? In some sense, that's what they are doing. They're looking at the thing and predicting what they think the label should be. Um, let's just call it like that. And then we are going to add on also our models prediction and we'll denote that by Pm. and the model is conditioning explicitly on the feature values, right? The classifier and what we're what you'll notice here is that we have weights, and what these weights allow us to do is they allow us to down weight an annotator that is bad, right? Give it less, give that annotator less impact on the resulting estimate of what we really think the true probability of each class is for this example. and they also allow us to up or down weight the classifier based on you know how good do we think the classifier is relative to a random annotator and that's a function of many things, right? Like the kind of data we're dealing with, how noisy all the annotators are and other issues like, and how many annotations we have per image. So even if you had really really bad annotators to begin with, but you had a hundred of them, look at each image and then you took majority vote labels and then trained your classifier. Your classifier might actually be a lot more accurate than any one of these annotators. And so the idea of the Crowd Lab Method is you will, uh, form this probability estimate of what the true class is for each example, and using that estimate you can just take the consensus label as the most likely class, and the confidence just becomes. You know the probability assigned to that most likely class under this estimate. And so in your lab assignment, you will see how we can produce these weights according to this Crowd Lab algorithm such that they properly account for. You know, down waiting, bad annotators, up waiting, good annotators, and accounting for how accurate the model is relative to each annotator. So any questions? Yes, yes, Exactly. So you can start with majority of out labels, train your classifier on the majority of out labels, compute this thing, then get new consensus labels, and retrain your classifier on those. And yes, it will converge. and in theory, it can get better and better. it can also get. There's one challenge, which is, if your model is really, really bad, then relying on the classifier can be dangerous. Of course, because you're relying on this extra source of information that is potentially misleading. Yeah, so I Did not at all talk about how we train the classifier. So a really simple way to do it is just to take majority vote labels and train it on those assuming those are noisy labels and then you can apply all the techniques we talked about in confident learning in the prior lecture to try and say which one of those are noisy. Based on the classifier's estimate, prune those. you could retrain the classifier and then use that classifier. There's a lot of things you could try and do to build, but here we're just assuming you've tried to build the best classifier. you can thank you any other questions. Wait, is that weight for the classifier change Depending on the data points? It's a constant weight. so you're just assuming the classifier is equally. It's just how accurate is the classifier relative to your average annotator and the details of it you will see in the lab assignment? Yes, yes, that is a method I did not have time to get into, but there is a method like Curtis showed that confident joint estimate. There's a method that stores something like that for each annotator and tries to estimate that. That is challenging though, because it really requires each annotator to have labeled a lot of data to really see how good they are at each class. Yeah, but that's actually how a lot of the classical algorithms in this space worked. Yes to rank them. Uh-huh Yeah, so you can just do this one time if you just do like in the lab assignment, you'll just do this one time. So you'll take, you'll have a classify, or you'll have just this data first, right? Then you'll form some kind of initial crude guess of what the best label for each example is. Train your classifier on that, then then estimate those distributions of the true class, and then just form a better consensus label based on that. But you could repeat the process again and as formally asked, it will converge if you repeat it multiple times. As long as your classifier training is stable, of course, there's a this: Whether how stable the training of a classifier is very much depend on the classifier converge, just means the consensus labels will remain stable. They won't change anymore. Getting it correct really depends on a lot of conditions. Yes, if you, if you have a hundred annotators labeling each example, you'll see in this formula here that this sum here over the annotators will dominate then versus over the classifier, right? So for such examples, Um, basically you would only be relying on the annotations and if 50 of the annotators all said it was class one and 50 said it was class two, uh, you would immediately this term would still dominate over the classifier's input and you would see that this is just fundamentally a really hard example because I've had 100 annotators look at it and 50 of them said this thing and 57. Another thing. The way I think about your question is that the classifier is vertical, so the class bar gets more information because this will look at all the data and all the images and then use all that information to get a good idea for each example and then the other method is annotated by majority voting. and that is horizontal. So you have horizontal across the Matrix that's one and then you've got vertical across the Matrix that's the other. And then this equation on the left is combining both horizontal and vertical and so that's why they each provide different information and additively to get more. Now you can keep iterating to do it multiple times, but yeah, you'll see even if you just do it once. it gives you a lot better estimates than something like Majority Vote because Majority Vote has so many problems like we talked about. Even just using the classifier to break ties and majority Vote gets you or something already much better due to having ties. Cool! Now with that, you will learn the details and see it working for yourself, hopefully in the lab assignment. I Think we're over time so thanks for coming.</div></div></div></div></div></div><div contenteditable="false" data-content-editable-void="true" style="width: 0px;"><div style="display: none; flex-shrink: 0; pointer-events: none; width: 0px; position: absolute; right: 192px; opacity: 0;"><div style="display: flex; flex-direction: column; padding: 5px 16px; width: 340px; flex-shrink: 0; height: 100%; position: relative; pointer-events: none; z-index: 1;"><div style="position: absolute; pointer-events: none; width: 100%; height: 100%; top: -5px; background: linear-gradient(white 0px, rgba(255, 255, 255, 0) 15px);"></div></div></div></div></main><span style="height: 1px; width: 1px;"></span></div><div class="notion-presence-container" style="position: absolute; top: 0px; left: 0px; z-index: 89;"><div></div></div></div></div></div><div class="notion-peek-renderer" style="position: fixed; top: 0px; right: 0px; bottom: 0px; width: 960px; z-index: 109; transform: translateX(960px) translateZ(0px);"></div></div></div></div></div><textarea aria-hidden="true" style="opacity: 0; pointer-events: none; position: fixed; left: 0px; top: 0px;"></textarea><textarea aria-hidden="true" style="opacity: 0; pointer-events: none; position: fixed; left: 0px; top: 0px;"></textarea><script src="assets/js/1172e9111a5fb396bcb8a05870b5eabf8abf221c.js" type="text/javascript"></script><div style="width: env(safe-area-inset-bottom);"></div></body></html>